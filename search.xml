<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[TensorFlow 模型保存与应用详解]]></title>
      <url>/tensorflow_model_save_use/</url>
      <content type="html"><![CDATA[<p>机器学习训练模型花费的时间一般都比较长，而机器学习是一个渐进的过程，因此，在训练的过程中进行模型的保存就重要。有时我们训练了一段很长的时间，如果突然断电等这些突发情况发生，如果没有即时备份，则又得重头开始训练。做好备份与恢复能大大提高我们模型训练的稳定性与效率。当然，备份也不能太频繁，太频繁也会降低训练效率。因此，在备份与训练效率之间的平衡也比较重要。</p>
<h2 id="1-模型保存与恢复"><a href="#1-模型保存与恢复" class="headerlink" title="1. 模型保存与恢复"></a>1. 模型保存与恢复</h2><p>TensorFlow 使用 Saver 类来进行模型的保存与恢复，它的作用就是保存与恢复变量。Saver 封装了很多实用方法来完成它的功能。例如它会自动管理备份文件以节省磁盘空间；也可以设置训练多长时间，保存一下备份文件。Saver 的构造函数如下。两个主要的方法分别为保存 save 与恢复 restore。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">tf.train.Saver.__init__(<span class="attribute">var_list</span>=None, <span class="attribute">reshape</span>=<span class="literal">False</span>, <span class="attribute">sharded</span>=<span class="literal">False</span>, <span class="attribute">max_to_keep</span>=5, <span class="attribute">keep_checkpoint_every_n_hours</span>=10000.0, <span class="attribute">name</span>=None, <span class="attribute">restore_sequentially</span>=<span class="literal">False</span>, <span class="attribute">saver_def</span>=None, <span class="attribute">builder</span>=None, <span class="attribute">defer_build</span>=<span class="literal">False</span>, <span class="attribute">allow_empty</span>=<span class="literal">False</span>, <span class="attribute">write_version</span>=2, <span class="attribute">pad_step_number</span>=<span class="literal">False</span>)</div><div class="line">在Saver的构造函数中，设置这些参数，则可以很方便地实现上面提到的功能。</div><div class="line">如：</div><div class="line">max_to_keep 可以设置最多保存多少个备份文件，如果超出了，则最早的因为已经没有用了，就会被删除。</div><div class="line">keep_checkpoint_every_n_hours 则可以让你设置训练多少个小时备份一下。</div><div class="line"></div><div class="line">tf.train.Saver.save(sess, save_path, <span class="attribute">global_step</span>=None, <span class="attribute">latest_filename</span>=None, <span class="attribute">meta_graph_suffix</span>=<span class="string">'meta'</span>, <span class="attribute">write_meta_graph</span>=<span class="literal">True</span>, <span class="attribute">write_state</span>=<span class="literal">True</span>)</div><div class="line">备份。返回备份文件名字。如果 global_step 设置了，则会将它添加在备份名字的最后。</div><div class="line"></div><div class="line">tf.train.Saver.restore(sess, save_path)</div><div class="line">恢复。</div></pre></td></tr></table></figure></p>
<p>一个通用的例子如下：<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line"><span class="meta"># 创建一个 Saver，来保存variables中指定的变量</span></div><div class="line">saver = tf.train.Saver(...variables...)</div><div class="line"><span class="meta"># 加载训练模型并开始训练。每1000次训练备份一次</span></div><div class="line">sess = tf.Session()</div><div class="line"><span class="keyword">for</span> <span class="keyword">step</span> <span class="keyword">in</span> xrange(<span class="number">1000000</span>):</div><div class="line">    sess.<span class="built_in">run</span>(..training_op..)</div><div class="line">    <span class="keyword">if</span> <span class="keyword">step</span> % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">        <span class="meta"># 将step保存在备份文件的名字中，好区分备份文件。</span></div><div class="line">        <span class="meta"># 每次备份的名字为 my-model-step</span></div><div class="line">        saver.save(sess, <span class="string">'my-model'</span>, global_step=<span class="keyword">step</span>) ==&gt; filename: <span class="string">'my-model-0'</span></div></pre></td></tr></table></figure></p>
<h2 id="2-模型应用"><a href="#2-模型应用" class="headerlink" title="2. 模型应用"></a>2. 模型应用</h2><p>模型训练结束后，会保存备份文件。当要应用模型时，可以先恢复模型，然后直接根据模型，计算出结果即可。<br>注意，在应用模型时，要把输入数据转成和训练数据相应的数据结构与类型。如对于手写数据识别，你应该把要识别的数字图片先经过预处理，转成28x28的的形式，再提交给训练好的模型使用。</p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python 学习集锦]]></title>
      <url>/python_learn_tips/</url>
      <content type="html"><![CDATA[<h2 id="1-语法基本"><a href="#1-语法基本" class="headerlink" title="1. 语法基本"></a>1. 语法基本</h2><ol>
<li><p>数组切分</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">arr = <span class="string">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></div><div class="line">arr<span class="string">[:4]</span> =&gt; <span class="string">[0, 1, 2, 3]</span></div><div class="line">arr<span class="string">[4:]</span> =&gt; <span class="string">[4, 5, 6, 7, 8, 9]</span></div><div class="line">arr<span class="string">[4:6]</span> =&gt; <span class="string">[4, 5]</span></div></pre></td></tr></table></figure>
</li>
<li><p>fake_image = [1] + [0] * 9 =&gt; [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</p>
</li>
<li>[1 for _ in xrange(10)]  =&gt; [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</li>
<li><p>数组遍历</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">for item <span class="keyword">in</span> <span class="keyword">sequence</span>:</div><div class="line">  <span class="built_in">print</span> item</div><div class="line">for <span class="built_in">index</span> <span class="keyword">in</span> <span class="built_in">range</span>(len(<span class="keyword">sequence</span>)):</div><div class="line">  <span class="built_in">print</span> <span class="built_in">index</span>,<span class="keyword">sequence</span>[<span class="built_in">index</span>]</div><div class="line">for <span class="built_in">index</span>, item <span class="keyword">in</span> enumerate(<span class="keyword">sequence</span>):</div><div class="line">  <span class="built_in">print</span> <span class="built_in">index</span>, item</div></pre></td></tr></table></figure>
</li>
<li><p>字典遍历</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">dict=&#123;<span class="string">"a"</span>:<span class="string">"apple"</span>,<span class="string">"b"</span>:<span class="string">"banana"</span>,<span class="string">"o"</span>:<span class="string">"orange"</span>&#125; </div><div class="line"> </div><div class="line"><span class="builtin-name">print</span> <span class="string">"##########dict######################"</span> </div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dict: </div><div class="line">  <span class="builtin-name">print</span> <span class="string">"dict[%s]="</span> % i,dict[i] </div><div class="line"> </div><div class="line"><span class="keyword">for</span> (k,v) <span class="keyword">in</span>  dict.items(): </div><div class="line">  <span class="builtin-name">print</span> <span class="string">"dict[%s]="</span> % k,v </div><div class="line"> </div><div class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> dict.iteritems(): </div><div class="line">  <span class="builtin-name">print</span> <span class="string">"dict[%s]="</span> % k,v </div><div class="line"> </div><div class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> zip(dict.iterkeys(),dict.itervalues()): </div><div class="line">  <span class="builtin-name">print</span> <span class="string">"dict[%s]="</span> % k,v</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="2-类库基本"><a href="#2-类库基本" class="headerlink" title="2. 类库基本"></a>2. 类库基本</h2><ol>
<li>xrange() 函数用法与 range 完全相同，所不同的是生成的不是一个数组，而是一个生成器。xrange不会直接生成一个list，而是每次调用返回其中的一个值 </li>
<li>判断文件是否存在。<figure class="highlight pf"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">import <span class="keyword">os</span></div><div class="line"><span class="keyword">os</span>.path.exists(dirOrFile) <span class="comment"># 可以同时判断文件或者文件夹，当文件夹和文件名字一样时，会误判</span></div><div class="line"><span class="keyword">os</span>.path.isFile(file) <span class="comment"># 只判断文件是否存在</span></div><div class="line"><span class="keyword">os</span>.path.isdir(dir) <span class="comment"># 只判断文件夹是否存在</span></div><div class="line"></div><div class="line"><span class="comment"># 下面两个，当要创建的目录有同名字的文件时，无法创建文件夹</span></div><div class="line"><span class="keyword">os</span>.mkdir(dir) <span class="comment"># 只创建一个目录</span></div><div class="line"><span class="keyword">os</span>.makedirs(dir) <span class="comment"># 级联创建目录</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="2-常见问题"><a href="#2-常见问题" class="headerlink" title="2. 常见问题"></a>2. 常见问题</h2><ol>
<li>如果要使用pip,注意将安装目录下的Scripts目录添加到环境变量中.</li>
<li>python 3 安装后,如果用pip安装文件,可能会提示安装visual c++ 14.用python 2,则没有这个问题,因为安装了vs 2013.</li>
</ol>
]]></content>
      
        <categories>
            
            <category> python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow MNIST 手写数字数据集详解]]></title>
      <url>/tensorflow_mnist_data/</url>
      <content type="html"><![CDATA[<p>学习编程语言，一般都以输出 Hello Wrold! 为第一个例子。MNIST 手写数字识别和 Hello World!一样，是机器学习中大家公认的第一个例子。但是有时，我们对 MNIST 这个专有名词 云里雾里，不知它到底是个什么东西。本文详细介绍MNIST是什么、有什么用、由哪些部分组成、数据结构是什么，最后用python把MNIST画出来，方便大家对它有一个直观认识。</p>
<h2 id="1-MNIST-是什么"><a href="#1-MNIST-是什么" class="headerlink" title="1. MNIST 是什么"></a>1. MNIST 是什么</h2><p>MNIST 是 Mixed National Institute of Standards and Technology database 的缩写，中文意思为混合美国国家标准与技术研究所数据库。MNIST的实际用途与它的名字基本无关联，你就把它当作一个专有名词看待就行了。</p>
<p>MNIST 是一个手写数字数据集，这个数据集中存储了很多不同人手写的0到9的数字。在这个数据集中，它的格式是经过处理了的。包括头部信息和每一张手写数字图片的像素灰度值信息。</p>
<h2 id="2-MNIST-作用"><a href="#2-MNIST-作用" class="headerlink" title="2. MNIST 作用"></a>2. MNIST 作用</h2><p>MNIST 的作用就是为你提供各种各样的手写数字，省去你收集手写数字、整理数字、格式化数字集等非常繁琐的工作。你可以用这个数据集来做各种你想做的事，比如你可以简单地看看别人写的数字是什么样的；或者用它来训练一个人工智能来识别数字，训练出来后，你可以用这个AI来识别银行支票、识别车牌、高考改卷等等。</p>
<h2 id="3-MNIST-组成"><a href="#3-MNIST-组成" class="headerlink" title="3. MNIST 组成"></a>3. MNIST 组成</h2><p>MNIST主要由两部分组成，一部分是训练数据集，一部分是测试数据集，总共有4个文件，如下图。它们都可以在网站<a href="http://yann.lecun.com/exdb/mnist/上下载。" target="_blank" rel="external">http://yann.lecun.com/exdb/mnist/上下载。</a><br><img src="/tensorflow_mnist_data/1.png" alt=""></p>
<p>训练数据集有两个文件，分别为 train-images-idx3-ubyte.gz、train-labels-idx1-ubyte.gz。测试数据集也是两个文件，分别为 t10k-images-idx3-ubyte.gz、t10k-labels-idx1-ubyte.gz。两个数据集中，文件名中有images的是包含了手写数字图片的数据；有labels的是数字标签数据，标示了和images文件中对应索引位置的手写数字图片是数字几。</p>
<h2 id="4-MNIST-数据格式"><a href="#4-MNIST-数据格式" class="headerlink" title="4. MNIST 数据格式"></a>4. MNIST 数据格式</h2><p>手写数字图片数据集格式如下。位移n表示解压后数据文件中第n位字节；字节数m表示位移n开始后的m个字节是一个整体，表示各种属性或图片数据。值表示第n位字节开始后的m个字节，表示的整型数值，这里的数据都是大端字节。</p>
<table>
<thead>
<tr>
<th>位移n</th>
<th>字节数m</th>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4</td>
<td>2051</td>
<td>魔法数字值，没什么作用，可能就是起版本号作用</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>60000</td>
<td>手写数字图片数量</td>
</tr>
<tr>
<td>8</td>
<td>4</td>
<td>28</td>
<td>每张手写数字图片中像素的行数</td>
</tr>
<tr>
<td>12</td>
<td>4</td>
<td>28</td>
<td>每张手写数字图片中像素的列数</td>
</tr>
<tr>
<td>16</td>
<td>784</td>
<td>b0,b2,b3…b783</td>
<td>第1张手写数字图片中每个像素的值</td>
</tr>
<tr>
<td>800</td>
<td>784</td>
<td>b0,b2,b3…b783</td>
<td>第2张手写数字图片中每个像素的值</td>
</tr>
<tr>
<td>1584</td>
<td>784</td>
<td>b0,b2,b3…b783</td>
<td>第3张手写数字图片中每个像素的值</td>
</tr>
<tr>
<td>…</td>
<td>784</td>
<td>b0,b2,b3…b783</td>
<td>每n张手写数字图片中每个像素的值，总共60000张</td>
</tr>
</tbody>
</table>
<p>手写数字图片中的数据为每个像素的灰度值。0表示白色，255表示黑色，中间的值则表示黑的程度，如128可能就表示灰色。如MNIST数据集中第一张图片5的数值如下图。<br><img src="/tensorflow_mnist_data/2.png" alt=""></p>
<p>手写数据标签数据集格式如下。</p>
<table>
<thead>
<tr>
<th>位移n</th>
<th>字节数m</th>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4</td>
<td>2051</td>
<td>魔法数字值，没什么作用，可能就是起版本号作用</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>60000</td>
<td>手写数字标签数量，和图片数量相对应</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>L</td>
<td>第1张手写数字图片对应的数字值，如L=5表示第一张图片对应的数字是5</td>
</tr>
<tr>
<td>9</td>
<td>1</td>
<td>L</td>
<td>第2张手写数字图片对应的数字值</td>
</tr>
<tr>
<td>10</td>
<td>1</td>
<td>L</td>
<td>第3张手写数字图片对应的数字值</td>
</tr>
<tr>
<td>…</td>
<td>1</td>
<td>L</td>
<td>第n张手写数字图片对应的数字值</td>
</tr>
</tbody>
</table>
<h2 id="5-MNIST-python-显示"><a href="#5-MNIST-python-显示" class="headerlink" title="5. MNIST python 显示"></a>5. MNIST python 显示</h2><p>根据上面MNIST的数据格式，可以用任何你喜欢的编程语言，把里面的数据读取出来，并显示在界面上。这里，我用python实现了一个读取器。它的功能为读取数据集中的图片数据与标签数据，并把读出的数字图片显示在界面上。如下图，可以通过界面下方的左右两个导航箭头，切换要显示的数字图片。<br><img src="/tensorflow_mnist_data/4.png" alt=""><br>读出的图片如下。<br><img src="/tensorflow_mnist_data/3.gif" alt=""><br>详细代码如下。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> struct</div><div class="line"><span class="keyword">import</span> gzip</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> matplotlib.backend_bases <span class="keyword">import</span> NavigationToolbar2</div><div class="line"></div><div class="line"><span class="comment"># plt 设置正常显示中文</span></div><div class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment">#用来正常显示中文标签</span></div><div class="line"></div><div class="line"><span class="comment"># 添加按钮的前进，后退，主页按钮事件</span></div><div class="line"><span class="comment"># 可以用它们导航查看所有图片</span></div><div class="line">imageIndex = <span class="number">0</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_home</span><span class="params">(self, *args, **kwargs)</span>:</span></div><div class="line">    <span class="keyword">global</span> imageIndex</div><div class="line">    imageIndex = <span class="number">0</span></div><div class="line">    showImagesByIndex(imageIndex)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_back</span><span class="params">(self, *args, **kwargs)</span>:</span></div><div class="line">    <span class="keyword">global</span> imageIndex</div><div class="line">    imageIndex -= <span class="number">6</span></div><div class="line">    showImagesByIndex(imageIndex)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_forward</span><span class="params">(self, *args, **kwargs)</span>:</span></div><div class="line">    <span class="keyword">global</span> imageIndex</div><div class="line">    imageIndex += <span class="number">6</span></div><div class="line">    showImagesByIndex(imageIndex)</div><div class="line"></div><div class="line">NavigationToolbar2.home = new_home</div><div class="line">NavigationToolbar2.back = new_back</div><div class="line">NavigationToolbar2.forward = new_forward</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 读取压缩文件gz中的内容</span></div><div class="line">labelsFileName = <span class="string">'/tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz'</span></div><div class="line">labelsGzipFile = gzip.open(labelsFileName, <span class="string">'rb'</span>)</div><div class="line">labelsBuf = labelsGzipFile.read()</div><div class="line"></div><div class="line"><span class="comment"># 读取标签头信息</span></div><div class="line"><span class="comment"># '&gt;II' 表示大端字节，读取2个int型数据，即8个字节的头</span></div><div class="line">magic, numLabels= struct.unpack_from(<span class="string">'&gt;II'</span> , labelsBuf, <span class="number">0</span>)</div><div class="line">print(<span class="string">'标签魔法数字: '</span>, magic, <span class="string">'标签数: '</span>, numLabels)</div><div class="line"></div><div class="line"><span class="comment"># 得到指定索引位置的标签</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLabelByIndex</span><span class="params">(index)</span>:</span></div><div class="line">    label = struct.unpack_from(<span class="string">'&gt;B'</span>, labelsBuf, index + <span class="number">8</span>)</div><div class="line">    <span class="keyword">return</span> label[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 读取压缩文件gz中的内容到imagesBuf中</span></div><div class="line">imagesFileName = <span class="string">'/tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz'</span></div><div class="line">imagesGzipFile = gzip.open(imagesFileName, <span class="string">'rb'</span>)</div><div class="line">imagesBuf = imagesGzipFile.read()</div><div class="line"></div><div class="line"><span class="comment"># 读取数字图片头信息</span></div><div class="line">magic, numImages , numRows , numColumns = struct.unpack_from(<span class="string">'&gt;IIII'</span> , imagesBuf, <span class="number">0</span>)</div><div class="line">print(<span class="string">'图片魔法数字: '</span>, magic, <span class="string">'数字图片数: '</span>, numImages, <span class="string">', 图片像素行数: '</span>, numRows, <span class="string">', 图片像素列数: '</span>, numColumns)</div><div class="line">numPixels = numRows * numColumns</div><div class="line">fmtPixels = <span class="string">'&gt;'</span> + str(numPixels) + <span class="string">'B'</span></div><div class="line">headSize = struct.calcsize(<span class="string">'&gt;IIII'</span>) <span class="comment"># 计算头大小，也就是16</span></div><div class="line"></div><div class="line"><span class="comment"># 当index超出范围[0-numImages)时,将它转换成正确的index</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCorrectIndex</span><span class="params">(index)</span>:</span></div><div class="line">    <span class="keyword">if</span> index &lt; <span class="number">0</span> <span class="keyword">or</span> index &gt;= numImages:</div><div class="line">        index = index % numImages</div><div class="line">    <span class="keyword">return</span> index</div><div class="line"></div><div class="line"><span class="comment"># 得到指定索引位置的标签与图片</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getImageByIndex</span><span class="params">(index)</span>:</span></div><div class="line">    index = getCorrectIndex(index)</div><div class="line">    imgData = struct.unpack_from(fmtPixels, imagesBuf, index * numPixels + headSize)</div><div class="line">    imgData = np.array(imgData)</div><div class="line">    image = imgData.reshape(numRows, numColumns)</div><div class="line"></div><div class="line">    label = getLabelByIndex(index)</div><div class="line">    <span class="keyword">return</span> index, label, image,</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">printImageData</span><span class="params">(index)</span>:</span></div><div class="line">    print(<span class="string">'第 %d 张图片数据如下:'</span> % index)</div><div class="line">    index, label, image = getImageByIndex(index)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numRows):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(numColumns):</div><div class="line">            print(<span class="string">'%4d'</span> % image[i][j], end=<span class="string">""</span>)</div><div class="line">        print(<span class="string">'\n'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">showImagesByIndex</span><span class="params">(index)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</div><div class="line">        indexOfImage, labelOfImage, numberImage = getImageByIndex(index + i)</div><div class="line">        axes = plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i + <span class="number">1</span>)     <span class="comment">#将窗口分割</span></div><div class="line">        plt.imshow(numberImage, cmap = plt.cm.gray_r)</div><div class="line">        plt.title(<span class="string">'第'</span> + str(indexOfImage) + <span class="string">'张, 数字为:'</span> + str(labelOfImage))</div><div class="line">        axes.set_xticks([])</div><div class="line">        axes.set_yticks([])</div><div class="line">    plt.legend()</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveImagesByIndex</span><span class="params">(index)</span>:</span></div><div class="line">    plt.clf()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</div><div class="line">        indexOfImage, labelOfImage, numberImage = getImageByIndex(index + i)</div><div class="line">        axes = plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i + <span class="number">1</span>)     <span class="comment">#将窗口分割</span></div><div class="line">        plt.imshow(numberImage, cmap = plt.cm.gray_r)</div><div class="line">        plt.title(<span class="string">'第'</span> + str(indexOfImage) + <span class="string">'张, 数字为:'</span> + str(labelOfImage))</div><div class="line">        axes.set_xticks([])</div><div class="line">        axes.set_yticks([])</div><div class="line">    plt.savefig(<span class="string">'mnist'</span> + str(index) + <span class="string">'.png'</span>, dpi=<span class="number">200</span>)</div><div class="line"></div><div class="line"><span class="comment"># 打印第0张图片数所</span></div><div class="line">printImageData(<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment"># 保存前36张手写数据图片</span></div><div class="line"><span class="comment">#  for i in range(6):</span></div><div class="line">    <span class="comment">#  saveImagesByIndex(i * 6)</span></div><div class="line"></div><div class="line"><span class="comment"># 显示前6张图片数据</span></div><div class="line">showImagesByIndex(imageIndex)</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
            <category> MNIST </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> MNIST </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (六) 图像识别简单版]]></title>
      <url>/tensorflow_minst_easy/</url>
      <content type="html"><![CDATA[<p>视觉信息是人信息的主要获取来源，其次是听觉、触觉、嗅觉、味觉。它们的占比大致情况如下：视觉87%，听觉7%，触觉3%，嗅觉2%，味觉1%。差不多百分之九十的信息是通过视觉处理的。因此，让机器可以看，是人工智能的一个重大方向。当解决了这个问题时，生活中很多事情就可以在它的基础上，用机器来解决。首当其冲的是安保；然后就是机器可以自动驾驶，和驾驶有关的则也会被取代；小偷犯罪份子估计也得更加小心，天天有一个眼睛在天上看着你，无处可逃等等。从人类百分之九十的信息来源于视觉，简单类比，将来，至少百分之九十的事情可以通过机器来完成。</p>
<p>现在的机器视觉应该还是处在开始阶段，和人类或者动物的视觉还相差很远。</p>
<h2 id="MNIST-数据处理"><a href="#MNIST-数据处理" class="headerlink" title="MNIST 数据处理"></a>MNIST 数据处理</h2><h2 id="图像识别模型"><a href="#图像识别模型" class="headerlink" title="图像识别模型"></a>图像识别模型</h2><h2 id="图像识别损失函数"><a href="#图像识别损失函数" class="headerlink" title="图像识别损失函数"></a>图像识别损失函数</h2><h2 id="图像识别损失函数-1"><a href="#图像识别损失函数-1" class="headerlink" title="图像识别损失函数"></a>图像识别损失函数</h2>]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 安装过程总结]]></title>
      <url>/linux_install_summary/</url>
      <content type="html"><![CDATA[<h2 id="1-系统安装"><a href="#1-系统安装" class="headerlink" title="1. 系统安装"></a>1. 系统安装</h2><ol>
<li>启动盘制作。下载Universal USB Installer。在选项的第4步中，Set a persistent file size for storing changes.设为0。我有一次就是因没没有先0,制作的启动盘不能用。</li>
</ol>
<ul>
<li>安装的过程中，不联网，不更新。</li>
<li>安装方式。有清空数据，硬盘上所有数据都清空；有保留原系统，添加一个系统；整个盘安装；其它，可以指定安装位置。要选其它安装方式，可以指定哪些盘格式化，哪些盘数据保存，从而可以保留上个系统的用户数据。</li>
<li>在下面boot，不要去先/boot的位置，直接默认硬盘就行。我有一次就是选了，导致启动不了。</li>
<li>更新系统。可以不更新。更新后，我编译安装vim时，有些模块不能用。</li>
<li>显卡驱动修改。系统默认使用的是开源的nvidia显卡驱动。可以安装官网驱动，但不是简单的通过界面改选安装。这样会造成无法启动或者自动重复登陆的问题。正确的安装方式是，先卸载原有驱动，再安装。<br>如果显卡驱动不修改，会有dashboard 显示异常的情况或者会卡住的情况。</li>
</ul>
<h2 id="2-系统配置"><a href="#2-系统配置" class="headerlink" title="2. 系统配置"></a>2. 系统配置</h2><ol>
<li>hosts 修改成github上的。可以访问很多国外的网站与服务。</li>
</ol>
<ul>
<li>terminal 修改快捷键在菜单里设置。</li>
<li>sudo unable to resole host linux .在host 中添加hostname 127.0.0.1</li>
<li>源，清楚。直接在gui中清除即可 </li>
<li>输入法使用对中文支持更好的 fcitx<br>System Settings  –&gt;  Language Support，输入法框架选择fcitx。<figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install fcitx fcitx-<span class="keyword">table</span>-wubi</div></pre></td></tr></table></figure>
</li>
</ul>
<p>安装完之后重启。才能显示fcitx输入框架。添加输入法时，要勾选显示全部语言。<br>如果五笔，输入标点符号不能自动上屏，可以切换到搜狐拼音输入法里，设置。</p>
<ul>
<li><p>swap 设置  </p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat <span class="regexp">/proc/</span>sys<span class="regexp">/vm/</span>swappiness</div></pre></td></tr></table></figure>
</li>
<li><p>无线无法自动连接，要关闭无线再打开，才能连接。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">sudo<span class="built_in"> service </span>network-manager restart</div><div class="line">ifconfig wlan0 down</div><div class="line">ifconfig wlan0 up</div><div class="line">iwconfig</div><div class="line">ifconfig</div><div class="line"></div><div class="line"><span class="comment"># 显示网卡硬件信息</span></div><div class="line">sudo lshw -class network</div><div class="line"></div><div class="line">lspci -vvnn | grep Network</div><div class="line">lspci -vvnn | grep -A 9<span class="built_in"> Network </span>| grep Kernel</div></pre></td></tr></table></figure>
</li>
</ul>
<p>零时修改:<br>sudo sysctl vm.swappiness=10<br>永久修改:<br>sudo nano /etc/sysctl.conf<br>添加下面的内容到上面的配置文件中:<br>vm.swappiness=10<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">## 3. 软件安装</div><div class="line">3. 卸载不要的程序。配置阿里源。先不配置，先试用一段时间，再看。</div><div class="line">* tweek tool , dconf editor。先不安装。</div><div class="line">* 鼠标共享，用同版本的synergy.</div><div class="line">* 跨电脑传文件用Nitroshare.</div></pre></td></tr></table></figure></p>
<p>sudo apt-get install nitroshare<br><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">* 快速启动。用Launchy。可以不安装，使用win键，很方便。</div><div class="line">* zsh 安装。oh my zsh 安装。autojump, kill, <span class="keyword">ls</span> </div><div class="line">* cat <span class="string">/etc/shells</span>  <span class="comment"># 查看已安裝的shell</span></div><div class="line">* chsh -s <span class="string">/bin/zsh</span> <span class="comment"># 修改默认shell</span></div><div class="line">* sudo apt-get install autojump  <span class="comment"># 安装autojump. 并添加下行到.zshrc</span></div></pre></td></tr></table></figure></p>
<p>[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.sh<br><figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">* 文件浏览器 pantheon。可以不安装，安装它需要安装很多其它东西。要</div><div class="line">* vim 编译。如果不能编译，查找是哪个模块的问题，从而通过配置减去它。我编译的时候就说perl有问题，把perl相关不配置，编译通过。</div><div class="line">* vim 字体。 curiver<span class="built_in"> new </span>不正常，暂使用其它字体解决。现在又正常了，重装系统后正常。</div><div class="line">* chrome 安装。安装谷歌同步助手，同步所有插件。</div><div class="line"></div><div class="line">* 解压程序用 peazip。这个先不装，系统自带的可以满足使用。</div><div class="line">* git 图形界面用 smartgit.</div><div class="line">* cpu, mem, net用<span class="built_in"> monitor </span>indicator.这个方法显示网速有问题</div><div class="line">只显示网速，用 netspeed</div></pre></td></tr></table></figure></p>
<p>sudo add-apt-repository ppa:nilarimogard/webupd8<br>sudo apt-get update<br>sudo apt-get install indicator-netspeed<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="bullet">* </span>创建系统还原点。这个不用。它的还原点只是对/home文件的备份。</div><div class="line"><span class="bullet">* </span>安装xfce桌面系统。这个暂不用。显卡驱动安装后，显示正常。</div><div class="line"><span class="bullet">* </span>tmux， oh my tmux 安装。 安装tmux-yank解决复制粘贴问题。</div><div class="line">它解决了一个分屏的方案。但是复制粘贴很麻烦。</div><div class="line"><span class="bullet">* </span>安装screenkey 显示按键。这个先不装，直接用alt+tab就可以</div><div class="line"><span class="bullet">* </span>安装tilda 终端，f1从上面拉下来，很方便。并设置开机自动启动。并且用win+123可以快速切换应用。</div><div class="line"><span class="bullet">* </span>安装cairo dock。skippy-xd。先不装。系统自带的很方便。</div><div class="line"><span class="bullet">* </span>vim start folder 设置</div><div class="line"><span class="bullet">* </span>jdk install</div><div class="line"><span class="bullet">* </span>hexo install</div></pre></td></tr></table></figure></p>
<p>sudo apt-get install npm<br>sudo apt-get install nodejs-legacy<br>sudo apt-get install nodejs<br>sudo npm install hexo-cli -g</p>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>hexo init blog<br>cd blog<br>npm install<br>hexo server<br>```</p>
<h2 id="4-试用且不安装"><a href="#4-试用且不安装" class="headerlink" title="4. 试用且不安装"></a>4. 试用且不安装</h2>]]></content>
      
        <categories>
            
            <category> linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (五) 曲线拟合]]></title>
      <url>/tensorflow_curve_fitting/</url>
      <content type="html"><![CDATA[<p>前面几篇文章尽量用通俗的语言讲了TensorFlow的<a href="http://iwifigame.com/tensorflow_basic_understanding/">基本理解</a>、<a href="http://iwifigame.com/tensorflow_data_summary/">数据总结</a>、<a href="http://iwifigame.com/tensorflow_deep_understanding">深入理解</a>。接下来的将通过一个个实战用例、由浅入深、分门别类、一步步详细介绍曲线模拟、图像识别简单版、图像识别卷积版、AI写诗、图像识别LSTM等。</p>
<p>每篇文章会先分析这些实例实现的深层原理（为什么这样做？这样做的好处是什么？…），像前3篇文章一样，这些都尽量用通俗的语言简化出来。然后放上注释详细可运行的代码，保证写明白代码运行机制，且保证每一行代码都经过不断地修改与优化。最后附上代码运行过程展示，尽量使用图片、动态图等方式说明机器一步步学习的过程。</p>
<p>这些文章所使用的TensorFlow版本是目前最新的0.12.0-rc1也就是通常所说的1.2版本，如无必要，以后不再说明使用版本情况。</p>
<p>从前面几篇系列文章，我们知道用机器学习来完成某些事情，比直接通过硬编码来完成，其工作量直接从编码转移到了数据的收集。这大大减少了程序员编码的负担。这种变化就像工业革命一样，解放了人的体力劳动；而人工智能则是解放了脑力劳动。这个革命之后，当人体之外的体力与脑力都被替代了，必由外而向内革命，让人自身变得更强、更聪明、更长寿；同时也向地球之外，不断探索。所以乔布斯遗嘱，让他的后代去从事生物方面的事业，不得不说是远见。现在正是脑力劳动大量被替代的过程。先从机器容易从事的、简单的开始，一步步、全部替代。这是时代发展的必然，这也是我们有生之年可见的未来。</p>
<p>本文以曲线拟合为例子，详细说明基本的函数api、TensorFlow程序的基本结构、数据的直观展示等。这个程序虽然看上去简单，但其充分直观地体现了机器学习的代码结构与过程。</p>
<h2 id="1-曲线拟合原理"><a href="#1-曲线拟合原理" class="headerlink" title="1. 曲线拟合原理"></a>1. 曲线拟合原理</h2><p>给你一条复杂的曲线图，如图1-1，要你设计一种机制，使通过这种机制计算出的点能够尽可能地和这条曲线重合，这个过程就叫曲线拟合。当你面对这样的问题时，我们应该怎么做？<br><img src="/tensorflow_curve_fitting/curve_data.png" alt="1-1"></p>
<p>如果不使用计算机，我们可能是先观察曲线的形式，猜想其形状中应该有哪些数学公式。如在这个例子中，我们可能会猜测公式中有sin相关的成份，然后再加入什么x，x的平方，x的立方。最终通过解方程大概就能求出这个公式来拟合这条曲线了。用这个方法可以解决上面提出的问题。并且当数据超出这些给定的数据范围（x超出-20到20）时，能更好地拟合将来的数据。如图1-1。当数据超出给定训练结果时，如果你计算出的函数正好与原有的曲线函数相对应，则能很好地预测超出的值。</p>
<p>而如果用机器学习的方法，图1-2中的蓝线就是机器学习的结果。从图中可以看出，当测试数据超出训练数据范围（xf超出-20到20）时，结果与测试的结果根本就对不上。其中的原理在前面3篇文章中详细介绍过：这是由于人强于推理，可以很好地解决推理出的未见的事情；而机器现在比较笨，只能根据你给定的训练数值来模拟。测试数据超出训练范围，机器学习就不再知道应该怎么做。当然，可以把未见的测试数据不断地加入训练数据中，然后机器不断地学习新数据（知识），使其适应范围越来越广。这也是为什么人工智能一开始比较笨，而随着你越使用它，它会变得越来越聪明的原因。<br><img src="/tensorflow_curve_fitting/curve_fitting_test.png" alt="1-2"></p>
<p>机器学习，怎么解决这种曲线拟合的问题呢？机器来解决，我们就不能说像上面提到的人类解决的方法一样：直接把公式中有的成分先写出来，然后根据曲线中的数据，计算出相应的参数。因为曲线的形状有无数种，你对这一条曲线用某些数学公式可以拼凑出来，换一条曲线呢？换另外的曲线公式吗？还是把所有的已知的所有数学公式全部放一个式子里，让计算机去计算每个参数，如y=a<em>sin(x)+b</em>x+c<em>x</em>x+d<em>x</em>x<em>x+d</em>x<em>x</em>x…？先不说上面两种方法的可实现性，如果碰到曲线奇里八怪的，根本就不能由数学公式组合出来怎么办。上面的那两种方法显然不行。人来解决这样的问题也够呛。</p>
<p>当然这里，有一种简单统计学的方法，我在训练数据中保存足够的样例数据。然后你给我一个x,我根据这个x去查找x周围，对应的y取值。然后把这些y值，根据距离x的远近，简单加权（离x近的，权重大，远的，权重小），返回给你，曲线拟合完毕。但是这有一个问题，你必须保存大量数据，保证每个区域内都有足够的数据来让你预测出y值。在图1-1中，数据很小，很容易解决。而如果这样的数据分布很大，数据有几个G，几个T，就不能这样做了。</p>
<p>机器解决曲线拟合问题的本质是要设计一种方便且简单可运行的机制，来预测的曲线。曲线中的每个点中的x可以看成元素x，而其y值可以看成结果。机器学习就是要学习元素x到结果y的对应关系。 前面几篇文章讲了，机器学习通过最简单的y=Wx+b来表示属性x到结果y的映射，由于(x,y)形状的千变万化（这里就是曲线形式千变万化），因此，要想让y=Wx+b体现这些变化，必需加入各种非线性的激活函数如sigmoid、tanh等。具体原理请参考系列的前3篇文章。因此，曲线拟合也是这样处理，我们先计算Wx+b,然后通过组合激活函数，来模拟任意形状的曲线。 这种方法，无需参想y=f(x)中有哪些形式和有多少个的各种表达式；也无需保存足够的数据样本，只需要训练出相关参数，保存即可。而且其拟合过程比以上说的方法都更快，更好。其基于Tensorflow的具体代码请看下面的代码详解。</p>
<h2 id="2-代码详解"><a href="#2-代码详解" class="headerlink" title="2. 代码详解"></a>2. 代码详解</h2><h4 id="2-1-数据生成"><a href="#2-1-数据生成" class="headerlink" title="2.1 数据生成"></a>2.1 数据生成</h4><p>我们用y=400<em>np.sin(x)+2</em>x*x+noise来生成要模拟的曲线，其中的noise是随机生成的噪点。生成的训练数据如下图。<br><figure class="highlight rsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta"># 生成测试数据根据x计算y值</span></div><div class="line">def computeYByX(x):</div><div class="line">    <span class="built_in">noise</span> = np.<span class="built_in">random</span>.<span class="keyword">normal</span>(<span class="number">-100</span>, <span class="number">100</span>, x.shape) <span class="meta"># 以正太分布的形式产生噪点</span></div><div class="line">    <span class="keyword">return</span> <span class="number">400</span> * np.<span class="built_in">sin</span>(x) + <span class="number">2</span> * x * x + <span class="built_in">noise</span></div></pre></td></tr></table></figure></p>
<p><img src="/tensorflow_curve_fitting/curve_data.png" alt=""></p>
<h4 id="2-2-数据表示"><a href="#2-2-数据表示" class="headerlink" title="2.2 数据表示"></a>2.2 数据表示</h4><p>可以用Pylot在直角坐标系上很直观方便地画出曲线(x,y)以及学到的曲线。代码中乃至的Pylot图表的相关介绍，请查看我的<a href="http://iwifigame.com/python_draw_image/">这篇文章</a>。其中用到的最主要代码如下。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 画点</span></div><div class="line">plt.plot(xTrain[<span class="number">0</span>], yTrain[<span class="number">0</span>], <span class="string">'ro'</span>, label = <span class="string">u'训练数据'</span>)</div><div class="line"><span class="comment"># 画线</span></div><div class="line">plt.plot(xTrain[<span class="number">0</span>], y.eval(&#123;x: xTrain&#125;, sess)[<span class="number">0</span>], label = <span class="string">u'拟合曲线'</span>)</div></pre></td></tr></table></figure></p>
<h4 id="2-3-曲线模拟形式选择"><a href="#2-3-曲线模拟形式选择" class="headerlink" title="2.3 曲线模拟形式选择"></a>2.3 曲线模拟形式选择</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">y</span> = tf.matmul(x, W3) + b3</div></pre></td></tr></table></figure>
<p>看上面的代码，我们用单层的网络。计算线性的x*W3+b3。如果加入非线性的sigmoid激活函数，改变Wx+b的值，改为 y = tf.nn.sigmoid(tf.matmul(x, W3) + b3)等相关形式，理论上应该能更好地模拟曲线。但实际的运行结果要么是直线，要么是各种上下不断交错。然后损失值下降不明显。如下图，是训练1万次之后的结果。我分析，应该是由于W与b的初值选得不好，造成sigmoid的中传入的参数值要么太大，要么太小，从而造成sigmoid值的梯度变化基本为0。因此达不到训练的结果。大家如果有什么更好的解释，可以在下面留言一起讨论。我是觉得用单层网络y = tf.nn.sigmoid(tf.matmul(x, W3) + b3)肯定能很好地模拟曲线的。<br><img src="/tensorflow_curve_fitting/curve_fitting_1_sigmoid.png" alt=""></p>
<p>经过测试，如果直接用y=tf.matmul(x, W3)+b3来做为单层网络，可以比较好的解决曲线拟合问题。但这与我们的目标不符。因此，经过查找与测试研究，终于找到了加入sigmoid激活函数且对各种曲线模拟通用性都比较好曲线模拟办法。通过加入两层网络，如下。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">def bias_variable(shape):</div><div class="line">  initial = tf.constant(0.1, shape=shape)</div><div class="line">  return tf.Variable(initial)</div><div class="line"></div><div class="line">hiddenDim = 400</div><div class="line"></div><div class="line">W = weight_variable([hiddenDim, 1]) <span class="comment"># W 被初始化为 hiddemDimX1 的符合正态分布的随机矩阵</span></div><div class="line">b = bias_variable([hiddenDim,1])</div><div class="line"></div><div class="line">W2 = weight_variable([1, hiddenDim])</div><div class="line">b2 = bias_variable([1])</div><div class="line"></div><div class="line">hidden = tf.nn.sigmoid(tf.matmul(W, x) + b)</div><div class="line">y = tf.matmul(W2, hidden) + b2</div></pre></td></tr></table></figure></p>
<p>在这种方法中，对W,b的初值选取没有第一种方法那么严格。而且如果模拟的结果不甚理想时，可以简单地加大W与b 中的维度hiddenDim的值，就可得到更好的模拟结果。</p>
<h4 id="2-4-损失与优化"><a href="#2-4-损失与优化" class="headerlink" title="2.4 损失与优化"></a>2.4 损失与优化</h4><p>这里没什么可说的，定义y与训练值yTrain之间差的平方的平均值为损失函数。然后就是选择优化算法，不详细解释。现在就知道它们会通过某些机制，让损失函数值loss越来越小，也就代表曲线越来越重合，直到训练过程完毕。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="attr">loss</span> = tf.reduce_mean(tf.square(y - yTrain)) # 以y之间的差的平方的均值为损失函数</div><div class="line"><span class="attr">step</span> = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</div><div class="line"><span class="attr">rate</span> = tf.train.exponential_decay(<span class="number">0.15</span>, step, <span class="number">1</span>, <span class="number">0.9999</span>)</div><div class="line"><span class="attr">optimizer</span> = tf.train.AdamOptimizer(rate)</div></pre></td></tr></table></figure></p>
<h4 id="2-5-训练"><a href="#2-5-训练" class="headerlink" title="2.5 训练"></a>2.5 训练</h4><p>用上面定义的损失函数与优化方法定义训练过程。不断地在上一步训练结果的基础上，叠代循环训练了10001次。每次理论上都不断地减少了y与yTrain之间的差距，即曲线拟合得越来越好。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">train = optimizer.minimize(loss, <span class="attribute">global_step</span>=step)</div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"><span class="comment"># Launch the graph</span></div><div class="line">sess = tf.Session()</div><div class="line">sess.<span class="builtin-name">run</span>(init)</div><div class="line"></div><div class="line"><span class="keyword">for</span> time <span class="keyword">in</span> range(0, 10001):</div><div class="line">    train.<span class="builtin-name">run</span>(&#123;x: xTrain&#125;, sess)</div></pre></td></tr></table></figure></p>
<h4 id="2-6-测试训练结果"><a href="#2-6-测试训练结果" class="headerlink" title="2.6 测试训练结果"></a>2.6 测试训练结果</h4><p>生成测试数据，用训练出的y表达式，计算出y值。把测试数据与训练计算结果显示在图上。如下，这里用超出训练数据范围的数据作用测试数据，看超出范围时，机器学习的学习成果是否正确。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">xTest = np.linspace(-<span class="number">40</span>, <span class="number">40</span>, <span class="number">401</span>).reshape([<span class="number">1</span>, -<span class="number">1</span>])</div><div class="line">yTest = computeYByX(xTest)</div><div class="line"></div><div class="line"><span class="comment"># 在坐标图上，显示最终训练的结果</span></div><div class="line">plt.clf()</div><div class="line">plt.plot(xTest[<span class="number">0</span>], yTest[<span class="number">0</span>], <span class="string">'go'</span>, label=<span class="string">u'测试数据'</span>)</div><div class="line">plt.plot(xTest[<span class="number">0</span>], y.eval(&#123;x: xTest&#125;, sess)[<span class="number">0</span>], label = <span class="string">u'拟合曲线'</span>) <span class="comment"># 将训练数据用圆点的形式显示出来</span></div><div class="line">plt.legend()</div><div class="line">plt.savefig(<span class="string">'curve_fitting_test.png'</span>,dpi=<span class="number">200</span>)</div><div class="line">plt.show() <span class="comment"># 将曲线学习结果用图片直观的显示出来</span></div></pre></td></tr></table></figure></p>
<p>这就是曲线模拟的所有过程。所有的机器学习过程基本上是这样：先定义训练数据表示形式；再设计元素x到结果y的映射；然后定义损失函数、选择优化方法；最终训练并验证训练结果。</p>
<p>由于代码太长，详细代码放在本文最后。</p>
<h2 id="3-运行过程与结果"><a href="#3-运行过程与结果" class="headerlink" title="3. 运行过程与结果"></a>3. 运行过程与结果</h2><p>生成的训练数据如下图，x的取值范围由-20到20。<br><img src="/tensorflow_curve_fitting/curve_data.png" alt=""><br>训练过程的动态图如下，可以看到训练出的曲线与训练数据不断拟合。<br><img src="/tensorflow_curve_fitting/cur_fitting_train.gif" alt=""><br>测试结果如下。从图中看出，当测试结果x在训练数据x的范围内时，其曲线拟合结果很好。但当一超出训练数据x的范围（超出-20到20），曲线拟合就完全对不上，变成了直线。<br><img src="/tensorflow_curve_fitting/curve_fitting_test.png" alt=""></p>
<h2 id="4-详细代码"><a href="#4-详细代码" class="headerlink" title="4. 详细代码"></a>4. 详细代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># 导入TensorFlow</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入多维数组操作库</span></div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入画图类库</span></div><div class="line"></div><div class="line"><span class="comment"># plt 设置正常显示中文与负号</span></div><div class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment">#用来正常显示中文标签</span></div><div class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="keyword">False</span> <span class="comment">#用来正常显示中文标签时的负号</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeYByX</span><span class="params">(x)</span>:</span></div><div class="line">    noise = np.random.normal(<span class="number">-100</span>, <span class="number">100</span>, x.shape) <span class="comment"># #產生100個平均0, 標準差0.2的干扰值</span></div><div class="line">    <span class="keyword">return</span> <span class="number">400</span> * np.sin(x) + <span class="number">2</span> * x * x + noise</div><div class="line">    <span class="comment">#  return np.sin(x)</span></div><div class="line"></div><div class="line">xTrain = np.linspace(<span class="number">-20</span>, <span class="number">20</span>, <span class="number">401</span>).reshape([<span class="number">1</span>, <span class="number">-1</span>]) <span class="comment"># xTrain为 1x401 数值在-20到20之间平均分布的矩阵</span></div><div class="line">noise = np.random.normal(<span class="number">-0.2</span>, <span class="number">0.2</span>, xTrain.shape) <span class="comment"># #產生100個平均0, 標準差0.2的干扰值</span></div><div class="line">yTrain = computeYByX(xTrain)</div><div class="line"></div><div class="line"><span class="comment"># 保存初始训练数据图片</span></div><div class="line">plt.clf() <span class="comment"># 清空plt画板</span></div><div class="line">plt.plot(xTrain[<span class="number">0</span>], yTrain[<span class="number">0</span>], <span class="string">'ro'</span>, label = <span class="string">u'训练数据'</span>) <span class="comment"># 将训练数据用圆点的形式显示出来</span></div><div class="line">plt.legend()  <span class="comment"># 显示图片中的图例说明。如点代表数据，蓝线代表拟合曲线</span></div><div class="line">plt.savefig(<span class="string">'curve_data.png'</span>,dpi=<span class="number">200</span>) <span class="comment"># 保存图片</span></div><div class="line"></div><div class="line"><span class="comment"># x 被定义为 1xNone 的占位符，None表示可以是任意值，根据喂的数据来定。</span></div><div class="line"><span class="comment"># 这里由于训练时喂的是xTrain,因此None到时被替换为401，也可以写成401</span></div><div class="line">x = tf.placeholder(tf.float32, [<span class="number">1</span>,<span class="number">401</span>])</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>) <span class="comment"># 从正态分布中得到随机值</span></div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line">hiddenDim = <span class="number">400</span></div><div class="line"></div><div class="line">W = weight_variable([hiddenDim, <span class="number">1</span>]) <span class="comment"># W 被初始化为 hiddemDimX1 的符合正态分布的随机矩阵</span></div><div class="line">b = bias_variable([hiddenDim,<span class="number">1</span>])</div><div class="line"></div><div class="line">W2 = weight_variable([<span class="number">1</span>, hiddenDim])</div><div class="line">b2 = bias_variable([<span class="number">1</span>])</div><div class="line"></div><div class="line">W3 = weight_variable([<span class="number">401</span>, <span class="number">401</span>]) <span class="comment"># W 被初始化为 hiddemDimX1 的符合正态分布的随机矩阵</span></div><div class="line">b3 = bias_variable([<span class="number">1</span>,<span class="number">401</span>])</div><div class="line"></div><div class="line">hidden = tf.nn.sigmoid(tf.matmul(W, x) + b)</div><div class="line">y = tf.matmul(W2, hidden) + b2</div><div class="line"></div><div class="line"><span class="comment">#  y = 2*(tf.nn.sigmoid(tf.matmul(x, W3) + b3) - 0.5)</span></div><div class="line"><span class="comment">#  y = tf.matmul(x, W3) + b3</span></div><div class="line"></div><div class="line"><span class="comment"># Minimize the squared errors.</span></div><div class="line">loss = tf.reduce_mean(tf.square(y - yTrain)) <span class="comment"># 以y之间的差的平方的均值为损失函数</span></div><div class="line">step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</div><div class="line">rate = tf.train.exponential_decay(<span class="number">0.15</span>, step, <span class="number">1</span>, <span class="number">0.9999</span>)</div><div class="line">optimizer = tf.train.AdamOptimizer(rate)</div><div class="line">train = optimizer.minimize(loss, global_step=step)</div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"><span class="comment"># Launch the graph</span></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line"><span class="keyword">for</span> time <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10001</span>):</div><div class="line">    train.run(&#123;x: xTrain&#125;, sess)</div><div class="line">    <span class="keyword">if</span> time % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">        print(<span class="string">'训练次数：'</span>, time, <span class="string">'，训练平均损失值：'</span>, loss.eval(&#123;x: xTrain&#125;, sess))</div><div class="line"></div><div class="line">        plt.clf()</div><div class="line">        plt.plot(xTrain[<span class="number">0</span>], yTrain[<span class="number">0</span>], <span class="string">'ro'</span>, label=<span class="string">u'训练数据'</span>)</div><div class="line">        plt.plot(xTrain[<span class="number">0</span>], y.eval(&#123;x: xTrain&#125;, sess)[<span class="number">0</span>], label = <span class="string">u'拟合曲线'</span>) <span class="comment"># 将训练数据用圆点的形式显示出来</span></div><div class="line">        plt.legend()</div><div class="line">        plt.savefig(<span class="string">'curve_fitting_'</span> + str(int(time/<span class="number">1000</span>)) + <span class="string">'.png'</span>,dpi=<span class="number">200</span>)</div><div class="line"></div><div class="line"><span class="comment"># 在坐标图上，显示最终训练的结果</span></div><div class="line"></div><div class="line">xTest = np.linspace(<span class="number">-40</span>, <span class="number">40</span>, <span class="number">401</span>).reshape([<span class="number">1</span>, <span class="number">-1</span>])</div><div class="line">yTest = computeYByX(xTest)</div><div class="line"></div><div class="line"><span class="comment"># 在坐标图上，显示最终训练的结果</span></div><div class="line">plt.clf()</div><div class="line">plt.plot(xTest[<span class="number">0</span>], yTest[<span class="number">0</span>], <span class="string">'mo'</span>, label=<span class="string">u'测试数据'</span>)</div><div class="line">plt.plot(xTest[<span class="number">0</span>], y.eval(&#123;x: xTest&#125;, sess)[<span class="number">0</span>], label = <span class="string">u'拟合曲线'</span>) <span class="comment"># 将训练数据用圆点的形式显示出来</span></div><div class="line">plt.legend()</div><div class="line">plt.savefig(<span class="string">'curve_fitting_test.png'</span>,dpi=<span class="number">200</span>)</div><div class="line">plt.show() <span class="comment"># 将曲线学习结果用图片直观的显示出来</span></div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[算法 (一) 你真的懂冒泡吗]]></title>
      <url>/algorithms_bubble_sort/</url>
      <content type="html"><![CDATA[<p>如果现在让你写一个冒泡排序，估计很多人都不能写出来。甚至对于其原理也只能支支唔唔，含糊不清，说个大概。不是说这个算法有多难，而是我们当时，看的时候记得，也懂了。但随着时间的推移，慢慢忘记了。很多知识都是这样。</p>
<p>这篇文章的目的就是让你一生都记住冒泡排序，永远不忘记。让你在任何时间，任何地点，使用任何你会的语言，都能在十分钟之内写出正确的冒泡算法。</p>
<h2 id="1-冒泡是什么"><a href="#1-冒泡是什么" class="headerlink" title="1. 冒泡是什么"></a>1. 冒泡是什么</h2><p>要想随时随地都记住什么是冒泡排序，使用死记硬背肯定是不行的，即使当时你理解了它，随着时间推移也可能不行。想想现在你还能不能清楚地记得它，就知道这个方法是行不通的。</p>
<p>因此，我们需要一种记忆技巧，一种追本溯源方法，这里，我们直接思考冒泡的意思。冒泡是什么意思？这个简单，江里、湖里、杯子里的气泡，往水上冒，就叫冒泡。气泡越大，往上冒的速度就越快。</p>
<h2 id="2-冒泡排序又是什么"><a href="#2-冒泡排序又是什么" class="headerlink" title="2. 冒泡排序又是什么"></a>2. 冒泡排序又是什么</h2><p>冒泡排序为什么叫冒泡排序，而不叫其它的？事物的名字，一般直接反应了事物的本质。这是我们取名时，自然而然想到的，最容易理解，最容易记忆的。像电脑、天空、太阳、人工智能、深度学习等等，太多太多反应了事物的本质，名字不是随便取的。</p>
<p>因此，要记忆冒泡排序，肯定就得和冒泡这个自然现象联系起来。先看冒泡排序的 C 语言实现。如下。<br><figure class="highlight go"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 对数组 arr 中的前 len 个数进行冒泡排序</span></div><div class="line">void bubble_sort(<span class="keyword">int</span> arr[], <span class="keyword">int</span> <span class="built_in">len</span>) &#123;</div><div class="line">	<span class="keyword">int</span> i, j, temp;</div><div class="line">    <span class="comment">// i标示了数组最后，已经排好位置的最大数。</span></div><div class="line">    <span class="comment">// 随着排序的进行，数组最后i个数不再需要考虑，已经排好了</span></div><div class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="built_in">len</span> - <span class="number">1</span>; i++)</div><div class="line">        <span class="comment">// 从最开始第0个数开始，如果当前数j比它后面的</span></div><div class="line">        <span class="comment">//数j+1大，则交换，即往后冒。直到数组最后没排好序的位置。</span></div><div class="line">		<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="built_in">len</span> - <span class="number">1</span> - i; j++)</div><div class="line">			<span class="keyword">if</span> (arr[j] &gt; arr[j + <span class="number">1</span>]) &#123;</div><div class="line">				temp = arr[j];</div><div class="line">				arr[j] = arr[j + <span class="number">1</span>];</div><div class="line">				arr[j + <span class="number">1</span>] = temp;</div><div class="line">			&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>冒泡排序就是像自然中冒泡的现象一样，把数据排好序。解释如下。</p>
<p>想象有一个直上直下的圆筒，圆筒中装满了水。水中竖直悬浮着大大小小的气泡，圆筒中每个位置有且只有一个气泡。气泡由于浮力的作用，会不断地往上浮。每次从最下面的气泡开始，如果这个气泡碰到上面比它小的气泡，它就和这个小的气泡交换位置；如果这个气泡碰到上面比它大的气泡，它就保持不动，然后那个大的气泡接替它，继续这样往上浮，直到碰到圆筒最上面，已经排好序了的都比它大的气泡为止。随着气泡们这样不断地上浮，最终圆筒中的气泡，会变成大气泡在上，小气泡在下的排好序的形式，冒泡排序完毕。可以看见，越大的气泡，越会快速地上升到圆筒的顶端，这正好和气泡越大，往上冒的速度越快的自然现象不谋而合。这又让你不得不佩服取名者的智慧。<br><img src="/algorithms_bubble_sort/0.jpg" alt=""></p>
<p>一图胜千言。上面的解释，再结合下面的动态图，相信你会更加明了。相信在未来的某一天，你会一说冒泡排序，就会想到自然界中的冒泡现象，自然而然地写出冒泡排序算法。<br><img src="/algorithms_bubble_sort/1.gif" alt=""></p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow LSTM 详解]]></title>
      <url>/null/</url>
      <content type="html"><![CDATA[<figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#tf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias, input_size, state_is_tupe=Flase, activation=tanh)</span></div><div class="line">cell = tf.nn.rnn_cell.BasicLSTMCell(num_units, <span class="attribute">forget_bias</span>=1.0, <span class="attribute">input_size</span>=None, <span class="attribute">state_is_tupe</span>=Flase, <span class="attribute">activation</span>=tanh)</div><div class="line"><span class="comment">#num_units:图一中ht的维数，如果num_units=10,那么ht就是10维行向量</span></div><div class="line"><span class="comment">#forget_bias：还不清楚这个是干嘛的</span></div><div class="line"><span class="comment">#input_size:[batch_size, max_time, size]。假设要输入一句话，这句话的长度是不固定的，max_time就代表最长的那句话是多长，size表示你打算用多长的向量代表一个word，即embedding_size（embedding_size和size的值不一定要一样）</span></div><div class="line"><span class="comment">#state_is_tuple:true的话，返回的状态是一个tuple:(c=array([[]]), h=array([[]]):其中c代表Ct的最后时间的输出，h代表Ht最后时间的输出，h是等于最后一个时间的output的</span></div><div class="line"><span class="comment">#图三向上指的ht称为output</span></div><div class="line"><span class="comment">#此函数返回一个lstm_cell，即图一中的一个A</span></div></pre></td></tr></table></figure>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (四) Windows 安装]]></title>
      <url>/tensorflow_windows_install/</url>
      <content type="html"><![CDATA[<p>纸上得来终觉浅，觉知此事要躬行。从原理上说了TensorFlow 3 大篇（<a href="http://iwifigame.com/tensorflow_basic_understanding/">基本理解</a>，<a href="http://iwifigame.com/tensorflow_data_summary/">数据总结</a>，<a href="http://iwifigame.com/tensorflow_deep_understanding/">深入理解</a>），总感觉离它就是隔了那么一点点距离。就像你站在妹子面前，空有一堆武功，却不知如何施展。解决办法就是，把它安装好，好好体验一翻。</p>
<p>本文以用户最多的操作系统 Windows 为例，只讲最简单的 CPU 安装方法，因为我们大部分人可能只是想先大概了解一下 TensorFlow。等大家安装完，使用一段时间后，对 TensorFlow 越来越熟悉后，可以尝试其它复杂的安装方法。而不是一上来，就卡在安装上。大部分人学习新技术，都死在了环境的安装上。有了环境，就可以体验式学习，学习的速度是有着质的飞越的。这就像学游泳，在岸上是永远学不会的，一脚踹下去，深藏功与名，才是正道。</p>
<p>我们学习技术，可能是受以前生活的影响（电器稍微不注意就就坏），大部分人总怕一不小心就把电脑弄坏了。总小心翼翼地伺候着：不敢多装几个软件，怕磁盘满了；不敢胡乱折腾，怕电脑开不了机…。其实这也是学习技术的大忌。现在的电器不像以前了，大家使劲造吧，弄不坏的。软件可以装了又删；磁盘满了，可以清空；系统变慢了，可以优化一下，实在不行，可以上核武器，重装系统。目前为止，我还没有看见谁玩软件，能把电脑硬件弄坏的。我们需要这种放开手脚干的精神，这才是真正快速学技术的精神。不把电脑虐它个千万遍，怎对得起我3000大洋的血汗钱。</p>
<h2 id="1-TensorFlow-官网"><a href="#1-TensorFlow-官网" class="headerlink" title="1. TensorFlow 官网"></a>1. TensorFlow 官网</h2><p>中国把人家官网都禁了，在国内无法正常访问。我不知道这算不算国家的自相矛盾。上层说要大力发展人工智能，却把最大的人工智能官网屏蔽。让你有时真想ctmd，哪个sb做的。不过，这种小事难不倒我们万能的程序员。 方法如下。</p>
<ol>
<li>修改 Windows hosts文件。什么？不懂什么是hosts，没事，做技术久了，自然就懂了。现在就当我没说，照着下面做就可以了。</li>
</ol>
<p>打开C:\Windows\System32\drivers\etc中的host文件. 添加如下内容，保存，OK 搞定。打开<a href="https://www.tensorflow.org" target="_blank" rel="external">TensorFlow官网</a>，测试一下。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">64<span class="selector-class">.233</span><span class="selector-class">.188</span><span class="selector-class">.121</span>  <span class="selector-tag">www</span><span class="selector-class">.tensorflow</span><span class="selector-class">.org</span></div></pre></td></tr></table></figure></p>
<ol>
<li>TensorFlow 官网能打开后，主页如下。里面有 TensorFlow 的第一手资料，从安装到实例、到 API 等等。刚开始，多看看里面的教程，把相关代码复制粘贴，运行一遍，然后给每行代码添加注释。一轮下来，我保证你们每个人都会从心底里说，机器学习太简单了！<br><img src="/tensorflow_windows_install/1.png" alt=""></li>
</ol>
<h2 id="2-TensorFlow-Windows-安装"><a href="#2-TensorFlow-Windows-安装" class="headerlink" title="2. TensorFlow Windows 安装"></a>2. TensorFlow Windows 安装</h2><p>最新的安装教程都能从官网上找到。下面是最新版最简单的 TensorFlow Windows CPU版，使用 Python pip 进行安装的教程。<br>从官网介绍来看，现在 TensorFlow 在 Windows 上只支持 64 位的 3.5 版本的 Python。如果你是好几年前的32位的电脑，那下面的内容就可以不看了。</p>
<ol>
<li><p>安装Pythone 3.5（<a href="https://www.python.org/downloads/release/python-352/" target="_blank" rel="external">点击官网下载</a>。我是不推荐 Anaconda 安装方法，主要原因就是包太大，400多M。而官网版本，我安装使用后，也没出现什么问题。 在最下面的文件中，选择x86_64位版本的windows安装包，安装即可。</p>
</li>
<li><p>安装 TensorFlow。打开命令行，输入如下命令，等待安装，大概几十M（妈的，以前我还以为TensorFlow至少得几百M）,安装就完成了。非常简单。这是截止到2017年9月19日，最新版的安装方法。如果以后TensorFlow更新了，请大家访问官网，查找最新版的安装办法。</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/tensorflow/</span>windows<span class="regexp">/cpu/</span>tensorflow-<span class="number">0.12</span>.<span class="number">0</span>rc1-cp35-cp35m-win_amd64.whl</div></pre></td></tr></table></figure>
</li>
<li><p>测试。开始体验了。打开命令行，照着下面命令来输。如果一切结果正常，恭喜你，TensorFlow 环境搭建完毕。大家开始使劲造吧。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash"> python</span></div><div class="line">...</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import tensorflow as tf</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sess = tf.Session()</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(sess.run(hello))</span></div><div class="line">Hello, TensorFlow!</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; a = tf.constant(10)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; b = tf.constant(32)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(sess.run(a + b))</span></div><div class="line">42</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 超神之路之 First Blood 安装篇]]></title>
      <url>/linux_install/</url>
      <content type="html"><![CDATA[<p>本系列教程以我实际使用 Linux 经验出发，详细记录踩坑与过坑的过程。主要是想为大家减少被坑的次数，节约宝贵的时间。中间加入自己的一些小小的理解与总结。从系列标题可知，我们的目的就是为了超神，成为 Linux　高手。</p>
<p>本系列教程的硬件一件为 07 年的老 Dell 笔记本，型号为 Dell Vostro 1400, 内存 3G，CPU为32位Intel(R) Core(TM)2 Duo CPU T7250 @ 2.00GHz，显卡为</p>
<p>这是系列教程的第一篇，安装篇。如果你已经安装好了 Linux，那么恭喜你，你成功拿到了超神这路的一血．如果没有，则请详细阅读本篇．笔者可是经过重装n次(这里n大于等于５)，才安装好自己想要的 Linux。</p>
<h2 id="U-盘启动盘制作"><a href="#U-盘启动盘制作" class="headerlink" title="U 盘启动盘制作"></a>U 盘启动盘制作</h2><p>U 盘启动盘制作有很多工具，我也试过两个。这是安装过程中的第一坑。我最开始的时候用的是 Ultra ISO，用它制作 14.04版本的可以正常下装；但是制作 16.04 版本的，则死活不能安装。这让我一度怀疑是我电脑的问题。</p>
<h2 id="Linux-分区原理"><a href="#Linux-分区原理" class="headerlink" title="Linux 分区原理"></a>Linux 分区原理</h2><h2 id="Linux-安装方式"><a href="#Linux-安装方式" class="headerlink" title="Linux 安装方式"></a>Linux 安装方式</h2><h2 id="Linux-安装注意"><a href="#Linux-安装注意" class="headerlink" title="Linux 安装注意"></a>Linux 安装注意</h2>]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux Windows Mac 终极鼠标共享 Synergy]]></title>
      <url>/linux_windows_mac_share_mouse/</url>
      <content type="html"><![CDATA[<p>Synergy 是我用的，目前为止支持平台最多的、使用最方便、最稳定的鼠标与键盘共享软件。我还使用过只支持windows平台的Mouse without Borders键鼠共享软件,这是微软出品的只支持windows平台，如果你只想在windows电脑之间共享键鼠，不防使用它。同时我还用过其它的，但已不记得名字了。总的来说，Synergy除却后面提到的版本难找的缺点，它是这一类软件中最好的。<br><img src="/linux_windows_mac_share_mouse/0.png" alt=""></p>
<p>有了Synergy，从理论上来说，你可以用一套鼠标与键盘，同时控制多台电脑（理论上是最多15台）。同时它还支持剪贴板共享。也就是说你可以在不同的电脑之间，无逢地复制粘贴文字，这大大提高了工作效率。甚至它还支持鼠标拖拽来传送文件,但这个功能只支持windows与mac之间的传送。其具体功能支持如下图。<br><img src="/linux_windows_mac_share_mouse/1.png" alt=""></p>
<h2 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a>1. 下载</h2><p>Synergy在官网下载时，需要付费。土豪可以直接购买下载，毕竟开发者开发也不容易，并且购买的版本支持的功能更多，像什么加密等，Synergy如果从国内的下载站中去下载，要么是平台版本不全，如只有windows版，没有linux版或Mac版的；要么就是要Synergy的版号不同，而这可能造成键鼠无法共享。</p>
<p>笔者经过千辛万苦帮大家找到了最新版的包含全平台的Synergy的下载地址，但由于头条不支持在文章中写外部网站的地址，请大家访问我的网站iwifigame点com，里面有Synergy最新最全的下载。如果大家觉得作者找软件，写文章辛苦了，也可以在该网站中，小小地打赏一下。</p>
<p><a href="https://sourceforge.net/projects/synergy-stable-builds/files/" target="_blank" rel="external"><strong>Synergy 下载地址请点击</strong></a>  </p>
<p>打开笔者提供的<a href="https://sourceforge.net/projects/synergy-stable-builds/files/" target="_blank" rel="external">下载地址</a>，里面包括1.7.6到最新版的1.8.8。我们打开1.8.8文件夹，选择和你操作系统以及位数相对应的版本即可。windows版本中名字有x86的表示是32位系统，x64表示64位操作系统。在linux版本中，有deb和rpm两种安装包，你首先需要确认你的系统支持哪种安装包；同时linux安装包名中的i686表示32位系统，x86_64表示64位操作系统。</p>
<h2 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h2><p>下载后的Windows与Mac版本的，直接双击即可安装，非常方便。</p>
<p>下面简单介绍下Linux版本中ubuntu的安装。下载Synergy正确的文件后（注意要下载和自己linux系统相对应的版本，有deb rpm 还有32位与64位之分），我下载的是32位的deb包，名字是synergy-v1.8.8-stable-Linux-i686.deb。下载完成后，使用终端跳转到下载文件夹，执行下面的命令，即完成安装。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">sudo</span> <span class="selector-tag">dpkg</span> <span class="selector-tag">-i</span> <span class="selector-tag">synergy-v1</span><span class="selector-class">.8</span><span class="selector-class">.8-stable-Linux-i686</span><span class="selector-class">.deb</span></div></pre></td></tr></table></figure></p>
<h2 id="3-使用"><a href="#3-使用" class="headerlink" title="3. 使用"></a>3. 使用</h2><p>Synergy 的使用，要明确服务端与客户端这两个概念了。当电脑运行Synergy时，可以选择是当服务端还是客户端。如果选择当服务端则表示本电脑的鼠标与键盘将共享给所有连接的客户端使用。选择客户端则表示与服务端连接后，可以使用服务端的鼠标与键盘，客户端本地的键鼠则只能自己使用。</p>
<p>下面我以我电脑中的windows电脑为服务端，linux电脑为客户端为例，详细说明配置与使用的过程。</p>
<p>Synergy的主界面如下。它的使用步骤如下。<br><img src="/linux_windows_mac_share_mouse/main.png" alt=""></p>
<ol>
<li><p>基本设置，只需设置电脑屏幕的名称（<strong>这里非常重要</strong>）。在之后的使用中，都需要这个电脑屏幕名称。<br>具体设置方法如下。选择主界面上编辑菜单中的设置，在弹出的设置窗口中，修改屏幕名称即可。注意，每台电脑的屏幕名称要不一样。如下，我把我的Windows电脑的屏幕名设为win。linux电脑中也同样这样设置为linux。至此，服务端与客户端的电脑屏幕名称就都设置好了，分别为win与linux。<br><img src="/linux_windows_mac_share_mouse/2.png" alt=""></p>
</li>
<li><p>设置服务端。<br>选中主界面上的Server方框，然后选择交互配置，再点击设置服务端按钮。<br><img src="/linux_windows_mac_share_mouse/3.png" alt=""><br>弹出如下对话框。<br><img src="/linux_windows_mac_share_mouse/4.png" alt=""><br>对话框中有15个方格，表示每个方格中可以拖拽放入一块屏幕（第一步中设置的），因此最多支持15台电脑共享一套键鼠。从右上角拖拽显示器模样的图标到方格中，即可添加屏幕；把屏幕拖到左上角的垃圾箱图标即可删除屏幕。双击拖拽添加好的屏幕，将添加的屏幕名设置为第1步中指定的屏幕名称。<br>我这里由于有两台电脑要相互连接，因此，添加两块屏幕，名称分别为win与linux。注意，这些屏幕的的相对位置最好对应现实中屏幕的位置。因为我的windows电脑在linux电脑的左边，因此名为win的屏幕放在名为linux的左边，这样才可以无逢切换鼠标。其它上下左右的设置也是这个道理。<br>在这里同时要记下服务端的IP地址，它的值为Server下中的IP地址指定的加粗的部分，这里为192.168.1.100。客户端在配置连接时，需要用到这个服务端ip地址。</p>
</li>
<li><p>设置客户端。选中主界面上的Client方框，然后在服务端IP中输入第二步中服务端的IP地址192.168.1.100。如下图。<br><img src="/linux_windows_mac_share_mouse/5.png" alt=""></p>
</li>
<li><p>启动服务端与客户端。分别点击服务端与客户端主界面上右下角的开始按钮即可。然后就可以在电脑间共享鼠标与键盘了，祝大家使用愉快。</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> windows </category>
            
            <category> mac </category>
            
            <category> synergy </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> windows </tag>
            
            <tag> mac </tag>
            
            <tag> synergy </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux Windows Mac 终极文件互传 Nitroshare]]></title>
      <url>/linux_windows_mac_transfer_file/</url>
      <content type="html"><![CDATA[<p>我们在不同电脑(Windows、linux、Mac)中工作时,总时不时地要传送文件到其它电脑。如果是两台电脑中都有qq,可以用它很好地解决这个问题。但现在qq越来越复杂庞大，而且必需登陆，登陆后，各种新闻弹出什么的非常烦。只是一个简单地传文件，用qq来解决没有这个必要。另一个方法就是把文件传到一些中转的地方，像网盘、邮箱等，但这一般要经过登陆、上传、下载三个步骤，也非常不方便和耗时间。</p>
<p>这里介绍一个非常简单的方法，通过使用开源跨平台文件传输软件itroshare，你只需要安装完毕后，直接运行，就可以在内网中，随时随地互相发送文件了。它非赏小巧基本不占用系统资源而且不需要登陆，非常简单实用。</p>
<p><img src="/linux_windows_mac_transfer_file/0.png" alt=""></p>
<h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h2><p>打开<a href="https://nitroshare.net/" target="_blank" rel="external">nitroshare官网</a>，在各个平台下载相应的安装包安装即可。这里简单说明一下linux的安装(以ubuntu为例)，其它版本的安装，都参照官网教程即可。<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="built_in">get</span> install nitroshare</div><div class="line">sudo apt-<span class="built_in">add</span>-repository <span class="keyword">pp</span><span class="variable">a:george</span>-edison55/nitroshare</div><div class="line">sudo apt-<span class="built_in">get</span> <span class="keyword">update</span></div><div class="line">sudo apt-<span class="built_in">get</span> install nitroshare</div></pre></td></tr></table></figure></p>
<h2 id="2-使用"><a href="#2-使用" class="headerlink" title="2. 使用"></a>2. 使用</h2><p>使用非常简单，先两台电脑都运行nitroshare，这里必须都运行，它是通过内网中运行它的电脑来标识身份，如果不运行，则发送文件时，找不到对方。然后选择要发送的文件或者文件夹。最后选择目标电脑，点击发送即可。<br><img src="/linux_windows_mac_transfer_file/1.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python 图表绘制 Pyplot]]></title>
      <url>/python_draw_image/</url>
      <content type="html"><![CDATA[<p>介绍TensorFlow用到的一般的常用画图api。不详细介绍每个api的参数，只大概举例说明。pyplot可以画很多不同的图表，下图显示了其中的6种，这样不同种类图还有很多种，只要你能想到的，一般都能用pyplot画出来。<br><img src="/python_draw_image/1.png" alt="pyplot 图表举例"></p>
<h2 id="1-图表中显示中文"><a href="#1-图表中显示中文" class="headerlink" title="1. 图表中显示中文"></a>1. 图表中显示中文</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt<span class="selector-class">.rcParams</span>[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] #用来正常显示中文标签</div><div class="line">plt<span class="selector-class">.rcParams</span>[<span class="string">'axes.unicode_minus'</span>]=False #用来正常显示中文标签时的负号</div></pre></td></tr></table></figure>
<h2 id="2-图表基本操作"><a href="#2-图表基本操作" class="headerlink" title="2. 图表基本操作"></a>2. 图表基本操作</h2><figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.title</span>(<span class="string">'图表标题'</span>)</div><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.clf</span>() # 清空<span class="selector-tag">plt</span>画板</div><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>(loc=<span class="string">'uper right'</span>)  # 显示图片中的图例说明。如点代表数据，蓝线代表拟合曲线</div><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'x'</span>) # 设置<span class="selector-tag">x</span>轴名字</div><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'y'</span>) # 设置<span class="selector-tag">y</span>轴名字</div><div class="line"><span class="selector-tag">plt</span><span class="selector-class">.savefig</span>(<span class="string">'curve_data.png'</span>,dpi=<span class="number">200</span>) # 保存图片</div></pre></td></tr></table></figure>
<h2 id="3-在坐标轴上显示数据"><a href="#3-在坐标轴上显示数据" class="headerlink" title="3. 在坐标轴上显示数据"></a>3. 在坐标轴上显示数据</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt.plot([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], <span class="string">'ro'</span>, label = <span class="string">u'训练数据'</span>) <span class="comment"># 将训练数据用红色圆点的形式显示出来</span></div><div class="line">plt.plot([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], label = <span class="string">u'拟合曲线'</span>) <span class="comment"># 将训练数据用线画出来</span></div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> pyplot </category>
            
            <category> python 画图 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> pyplot </tag>
            
            <tag> python 画图 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow stack 与 unstack 详细介绍]]></title>
      <url>/tensorflow_stack_and_unstack/</url>
      <content type="html"><![CDATA[<h2 id="1-tf-stack"><a href="#1-tf-stack" class="headerlink" title="1. tf.stack()"></a>1. tf.stack()</h2><p><strong>tf.stack(values, axis=0, name=’stack’)</strong><br><strong>以指定的轴axis，将一个维度为R的张量数组转变成一个维度为R+1的张量。即将一组张量以指定的轴，提高一个维度。</strong></p>
<p>假设要转变的张量数组的长度为N,其中的每个张量的形状为(A, B, C)。<br>如果轴axis=0，则转变后的张量的形状为(N, A, B, C)。<br>如果轴axis=1，则转变后的张量的形状为(A, N, B, C)。<br>如果轴axis=2，则转变后的张量的形状为(A, B, N, C)。其它情况依次类推。  </p>
<p>举例如下：<br>‘x’ is [1, 4]， 形状是(2)，维度为1<br>‘y’ is [2, 5]， 形状是(2)，维度为1<br>‘z’ is [3, 6]， 形状是(2)，维度为1<br>stack([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]]  # axis的值默认为0。输出的形状为(3, 2)<br>stack([x, y, z], axis=1) =&gt; [[1, 2, 3], [4, 5, 6]] # axis的值为1。输出的形状为(2, 3)</p>
<p>‘x’ is [[1,1,1,1],[2,2,2,2],[3,3,3,3]]，形状是(3,4)，维度为2<br>‘y’ is [[4,4,4,4],[5,5,5,5],[6,6,6,6]]，形状是(3,4)，维度为2<br>stack([x,y]) =&gt; [[[1,1,1,1],[2,2,2,2],[3,3,3,3]], [[4,4,4,4],[5,5,5,5],[6,6,6,6]]] # axis的值默认为0。输出的形状为(2, 3, 4)<br>stack([x,y],axis=1) =&gt; [[[1,1,1,1],[4,4,4,4]],[[2,2,2,2],[5,5,5,5]],[[3,3,3,3],[6,6,6,6]]] # axis的值为1。输出的形状为(3, 2, 4)<br>stack([x,y],axis=2) =&gt; [[[1,4],[1,4],[1,4],[1,4]],[[2,5],[2,5],[2,5],[2,5]],[[3,6],[3,6],[3,6],[3,6]]]# axis的值为2。输出的形状为(3, 4, 2)  </p>
<p><strong>axis可这样理解：stack就是要将一组相同形状的张量提高一个维度。axis就是这些张量里，将axis指定的维度用所有这些张量数组代替。如axis=2，表示指定在第2个维度，原来的元素用整个张量数组里的元素代替，即从(A, B, C)转变为(A, B, N, C)</strong></p>
<p><strong>参数:</strong><br>values: 一个有相同形状与数据类型的张量数组。<br>axis: 以轴axis为中心来转变的整数。默认是第一个维度即axis=0。支持负数。取值范围为[-(R+1), R+1)<br>name: 这个操作的名字（可选）<br><strong>返回:</strong><br>被提高一个维度后的张量。<br><strong>异常:</strong><br>ValueError: 如果轴axis超出范围[-(R+1), R+1).  </p>
<hr>
<h2 id="2-tf-unstack"><a href="#2-tf-unstack" class="headerlink" title="2. tf.unstack()"></a>2. tf.unstack()</h2><p><strong>tf.unstack(value, num=None, axis=0, name=’unstack’)<br>以指定的轴axis，将一个维度为R的张量数组转变成一个维度为R-1的张量。即将一组张量以指定的轴，减少一个维度。正好和stack()相反。</strong></p>
<p>将张量value分割成num个张量数组。如果num没有指定，则是根据张量value的形状来指定。如果value.shape[axis]不存在，则抛出ValueError的异常。</p>
<p>假如一个张量的形状是(A, B, C, D)。<br>如果axis == 0，则输出的张量是value[i, :, :, :],i取值为[0,A)，每个输出的张量的形状为(B,C,D)。<br>如果axis == 1，则输出的张量是value[:, i, :, :],i取值为[0,B)，每个输出的张量的形状为(A,C,D)。<br>如果axis == 2，则输出的张量是value[:, :, i, :],i取值为[0,C)，每个输出的张量的形状为(A,B,D)。依次类推。  </p>
<p>举例如下：<br>‘x’ is [[1,1,1,1],[2,2,2,2],[3,3,3,3]] # 形状是(3,4)，维度为2<br>unstack(x,axis=0) =&gt;以指定的维度0为轴，转变成3个形状为(4)张量[1,1,1,1],[2,2,2,2],[3,3,3,3]<br>unstack(x,axis=1) =&gt;以指定的维度1为轴，转变成4个形状为(3)张量[1,2,3],[1,2,3],[1,2,4],[1,2,3]  </p>
<p><strong>axis可这样理解：unstack就是要将一个张量降低为低一个维度的张量数组。axis就是将axis指定的维度，用所有这个张量里同维度的数据代替。 </strong></p>
<p><strong>参数:</strong><br>value: 一个将要被降维的维度大于0的张量。<br>num: 整数。指定的维度axis的长度。如果设置为None(默认值),将自动求值。<br>axis: 整数.以轴axis指定的维度来转变 默认是第一个维度即axis=0。支持负数。取值范围为[-R, R)<br>name: 这个操作的名字（可选）<br><strong>返回:</strong><br>从张量value降维后的张量数组。<br><strong>异常:</strong><br>ValueError: 如果num没有指定并且无法求出来。<br>ValueError: 如果axis超出范围 [-R, R)。  </p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (三) 深入理解]]></title>
      <url>/tensorflow_deep_understanding/</url>
      <content type="html"><![CDATA[<p>　　本文先不谈TensorFlow怎样通过深度学习来解决实际问题，而是先从设计的角度来说明如何设计深度学习框架。当然，这有些事后诸葛亮的味道，这里的假想设计都是从已知的资料中加入自己的一点点理解而来。</p>
<h2 id="1-什么是深度学习"><a href="#1-什么是深度学习" class="headerlink" title="1. 什么是深度学习"></a>1. 什么是深度学习</h2><p>　　要解决一件事情，我们首先得知道事情是什么。要设计一个深度学习框架，首先就要弄明白什么是深度学习。抛开一切晦涩难懂的公式与证明，我们就用自己的话来说明什么是深度学习。<br>　　首先，我们分词。深度学习分成两个词深度与学习。深度，就是不要浮于表面，要深入事物的本质。学习，就是你本来不懂某个东西，通过学习这个活动你就懂了。<br>　　然后，我们合词，深度学习就是深度与学习的组合。意思就是深入事物的本质，学会某件事情。这里有两个方面的要求，一是要深入事物的本质，二是要学会。<br>　　深入事物的本质有很多种方法与角度。其中一种是分割的方法，把事物不断分割，直到分割到你觉得合适为止。就像你想弄明白世间万物是由什么组成的，你就可以不断地分割，越来越细，直到分子、原子、原子核、中子质子、夸克…<br><img src="/tensorflow_deep_understanding/0.jpg" alt="细分到原子、原子核、中子。质子、电子"><br>比如你只想知道为什么水会变成水蒸气，就把水分割到分子的水平就可以理解了；但当你想知道石油为什么燃烧会有水产生，可能你就得细分到分子、原子甚至原子核的地步了。另一种常用的方法可能就是推理的方法了。由某一个事物，基于严密的逻辑推理，认识另一个事物。比如，我们知道勾股定理，从直角三角形的两条边长度，我们可以推理出第三条边的长度。<br><img src="/tensorflow_deep_understanding/1.jpg" alt="勾股定理"><br>　　而对于学会，什么才是学会？小时候，对于历史，可能我们记住了，就是学会了。对于数学呢？会解相应的题目才算学会。因此，我们定义学会就是通过学习，在被要求完成的某件事上，能完成这件事到指定的程度。如对于历史，你对小学生的学会要求和对历史学研究生的学会要求肯定不同吧。</p>
<h2 id="2-机器怎样深度学习"><a href="#2-机器怎样深度学习" class="headerlink" title="2. 机器怎样深度学习"></a>2. 机器怎样深度学习</h2><p>　　我们知道了什么是深度学习。机器和人天生的不同点决定了机器的学习方法与人的学习方法存在某些差异。别小看这些差异，正是这些差异，能让我们从根本上看清人与机器各自的擅长的领域。让机器去做它们比我们擅长的，我们做我们擅长的。而不是硬要去和机器比自己不擅长的领域，这比不赢也没必要，应该把机器当做我们的工具。时代的发展，就是机器不断替代人类擅长领域的发展。从体力劳动的不断被替换，到现在的部分脑力劳动的替换。发展到以后可能就是全部的替换，甚至机器在所有领域比我们都更擅长。<br>　　机器目前为止擅长的方面是动力、记忆、计算、不知疲倦。人相对机器来说，现在有些优点是机器无法比拟的，像逻辑推理与想象等。所以不要去和机器比谁力量大、记得多、算得快、谁更勤奋。而是要发挥你的聪明才智、发挥你的想象力、创造力去学和做机器不擅长的或者想办法让机器更聪明、更强壮。<br><img src="/tensorflow_deep_understanding/3.gif" alt="无人工厂"><br>　　我们知道深度学习是深入事物的本质，学会某件事情。深入事物有两种基本的方法，分别为分割与推理。由于现在机器还比较笨，不会推理，现在即使是会推理可能也只是表面上的会，假的会。因此，机器深度学习一般是通过分割来学习的。像我们要识别一张图片是狗还是猫。机器（当然这个算法由人来实现）把图片不断细分，直达像素级别，然后学习这些像素中的规律，把这种规律与是狗还是猫相对应起来。还有我们语音识别某一句话，假如是”你好”。机器则把音频中的波形数据不断分割，直到足够细，可以看成上上下下一个个的点。然后把这些点与语料库中的某些声音对应起来，从而识别出是你好。<br>　　因此，机器的深度学习，就是不断分割，找到规律，然后学会。要达到学会的目的，一条两条数据不行，你得给它大量数据。数据少，学到的只是某个特定的案例中的规律，离开这个特定的案例，机器就不会了，因为机器现在不像人一样，会推理学习。数据越多，学到的通用规律就越多，解决问题的正确性就越高。但案例即使够多，也无法穷尽所有可能性，因此，对于将来某些特定的案例，机器可能还是会出错，只是这种出错的概率会越来越低。因此，机器的深度学习就有一个衡量正确性的指标叫做错误率。它还有一个衡量错的程度的指标，这个指标有很多名字，如损失、交叉熵等。可以看出，机器学得越少，可能错得就越离谱。<br>　　在机器的深度学习中，最重要的就是要找到规律。以图像识别中最简单的数字识别来说，每一个分割到的像素点，怎样对应到0123456789？<br><img src="/tensorflow_deep_understanding/MNIST.png" alt="手写数字"><br><img src="/tensorflow_deep_understanding/MNIST-Matrix.png" alt="手写数字1的灰度像素值"><br>　　以1为例，图片中可以分为是1和不是1的部分。对于1中的像素点即图中不为0的像素点，我们会让这个像素点对于判断是1这个结果起正作用。对于不是1中的的像素点即为0的像素点，则对判断是1这个结果起负作用。那么这个正负作用应该怎样来体现？我们可以使每个像素对应一个权重b，正作用则b为正数，负作用b则为负数，数值越大，起的作用就越强。我们也可以让每个像素乘以一个数W,起正作用W为正数，负作用为负数，数值越大，作用也超强，越小，作用就越小。上面这两个是最简单的。复杂的呢也可以设计一些函数像像素的立方、像素的正弦值、像素的指数等等这些都可以。但一般选择这些函数要保证它的输出值有正有负，连续。有正有负能体现正负作用；连续能保证作用无穷变化。又由于一般用于机器学习的数据成千上万，要做的运算相当多，因此，一般选用最简单的乘W和加b来体现这种正负作用。下图为机器深度学习后，每个像素点对识别为数字0到9的正负作用示意图，其中蓝色为起正作用的像素点，红色则表示起反作用。<br><img src="/tensorflow_deep_understanding/softmax-weights.png" alt="数字的正负作用示意图"><br>　　假设事物不断分割到一个元素x，则这种正负作用就可以表示为 Wx+b。这是一个线性函数，即使我们不断把这些线性函数线性的组合，其最终还是一个线性函数，则只能学到那些线性的规律。但是事物的规律千变万化，因此我们就想要一种方法，使其能体现这种变化。也就等价于要使正负作用最终能以曲线的形式体现。如下图，其中的每一个点可以看成元素x的取值分布，其蓝黄两色分别对应两个要学习的结果如是1还是不是1，是2还是不是2。深度学习的目的就是要学习这种分布规律，找到一种把两种颜色区分开的方法。对于图1中的点，用Wx+b的很容易就区分开，只要从对角线划一条直线就可以了，也就是学习到W的值可能为-1，b为0。但是对于图2、3、4中的点，则没有那么简单，甚至不能用Wx+b的加减变化来区分这些点。</p>
<p><img src="/tensorflow_deep_understanding/devide.jpg" alt=""><br>　　怎样区分上图中2、3、4的点？如果不能模拟出曲线基本是不可能的。我们可以把正负作用用元素的指数、三角函数等这些来替换Wx+b中的x，就变成了Wsin(x)+b等等。这种方法，当然可以很好地解决我们的问题。但是，机器学习的过程是通过比较输出的结果与实际的结果之间的差异，来优化控制参数。而这种优化方法一般是通过向最快的优化方向前进的，这就要求通过计算来求出这个最快优化方向。因为我们不可能把所有方向都试一篇（变化方向无穷多个）然后看结果是变好了还是变差了。而是应该直接计算出一个当前看起来最好的方向，直接优化参数值，这样能大大减少运算时间。优化方向的选择就对应了求导的过程。而指数与三角函数等，对导数天然的不友好性，如求导公式复杂、可能不能简单的加减、多个元素组合后更加难求值以及无法用数学证明其最佳方向在哪等等，因此就不用元素的指数与三角函数这类表达式来定义正负作用。<br>　　由此，只剩下了简单的Wx+b来表示正负作用，怎样来区分2、3、4？假设A=Wx+b，我们可以对A的值再选一个函数来求值，只要A的形式是曲线，那就能模拟了。假设这条曲线的函数为g(A)。那对于上面提到与导数的友好性要求应该怎样解决？因为如果g(A)不好求导、或求导后，不能各个元素加减等，则和上面的指数与三角函数并没有本质的区别。因此，g(A)的选择就非常重要，不是所有函数都可以。g(A)一般要满足以下几个要求才行。</p>
<ol>
<li>非线性。如果它是线性的，则g(A)与Wx+b本质是一样的，无法模拟曲线。</li>
<li>可导性。要通过计算求得最做好的变化方向，必须要求导。</li>
<li>导数方便计算且导数易于加减计算等。<br>现在常用的g(A)如下。g(A)在深度学习中，有一个通用的名字叫做激活函数(Activation Function)。只要g(A)是下图中曲线形式，就能模拟任何曲线，因此就能很好的区分图2，3，4中的点。<br><img src="/tensorflow_deep_understanding/Activation Function.png" alt="激活函数"></li>
</ol>
<h2 id="3-TensorFlow怎样深度学习"><a href="#3-TensorFlow怎样深度学习" class="headerlink" title="3. TensorFlow怎样深度学习"></a>3. TensorFlow怎样深度学习</h2><p>　　TensorFlow的深度学习过程也和上面说的大同小异(其实上文就是通过学习TensorFlow而来)。</p>
<ol>
<li>首先把每个数据分割，进行处理，找到这些分割后的数据与数值的一一对应关系，我们假设某个分割点对应的数值为x。图像可能分割到像素点、声音分割到一个个波形点、文本分割成一个个字词。然后把这些数据表示成特定的数值。图像中像素点的RGB值直接可以用做x、波形点可以根据离中轨的距离表示为x、文本则要把每一个字词对应到数字表示为x。</li>
<li>找到合适的函数表达分割后的数值x与输出结果正负作用的关系f(x)。这里有两部分。第一部分是A=Wx+b。第二部分为激活函数g(A)。即f(x) = g(Wx + b)。</li>
<li>开始深度学习。对于每一条数据，根据f(x)的取值以及f(x)的导数等，寻找W与b的最优变化方向。更新W与b的取值。继续下一次训练。直到输出结果的正确率或者其它衡量指标达到自己的要求，停止训练。<br>　　当然上面是最简单的单层的深度学习网络。f(x)后面还可以接以f(x)的输出为输入的其它各种各样的f(x)，也可以连续接任意多层。理论上，层数越多，学习的效果越好。下图是个两层的学习网络，第一层以Relu为激活函数，第二层Logistic(logit)为激活函数。<br><img src="/tensorflow_deep_understanding/tensors_flowing.gif" alt=""></li>
</ol>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[skynet(一) 启动]]></title>
      <url>/skynet_bootstrap/</url>
      <content type="html"><![CDATA[<h2 id="1-skynet-结点"><a href="#1-skynet-结点" class="headerlink" title="1. skynet 结点"></a>1. skynet 结点</h2><h2 id="2-skynet-启动流程"><a href="#2-skynet-启动流程" class="headerlink" title="2. skynet 启动流程"></a>2. skynet 启动流程</h2><h2 id="3-skynet-配置文件"><a href="#3-skynet-配置文件" class="headerlink" title="3. skynet 配置文件"></a>3. skynet 配置文件</h2><p>skynet 由一个或多个进程构成，每个进程被称为一个 skynet 节点。本文描述了 skynet 节点的启动流程。</p>
<p>skynet 节点通过运行 skynet 主程序启动，必须在启动命令行传入一个 Config 文件名作为启动参数。skynet 会读取这个 config 文件获得启动需要的参数。</p>
<p>第一个启动的服务是 logger ，它负责记录之后的服务中的 log 输出。logger 是一个简单的 C 服务，skynet_error 这个 C API 会把字符串发送给它。在 config 文件中，logger 配置项可以配置 log 输出的文件名，默认是 nil ，表示输出到标准输出。</p>
<p>bootstrap 这个配置项关系着 skynet 运行的第二个服务。通常通过这个服务把整个系统启动起来。默认的 bootstrap 配置项为 “snlua bootstrap” ，这意味着，skynet 会启动 snlua 这个服务，并将 bootstrap 作为参数传给它。snlua 是 lua 沙盒服务，bootstrap 会根据配置的 luaservice 匹配到最终的 lua 脚本。如果按默认配置，这个脚本应该是 service/bootstrap.lua 。</p>
<p>如无必要，你不需要更改 bootstrap 配置项，让默认的 bootstrap 脚本工作。目前的 bootstrap 脚本如下：</p>
<p>local skynet = require “skynet”<br>local harbor = require “skynet.harbor”</p>
<p>skynet.start(function()<br>    local standalone = skynet.getenv “standalone”</p>
<pre><code>local launcher = assert(skynet.launch(&quot;snlua&quot;,&quot;launcher&quot;))
skynet.name(&quot;.launcher&quot;, launcher)

local harbor_id = tonumber(skynet.getenv &quot;harbor&quot;)
if harbor_id == 0 then
    assert(standalone ==  nil)
    standalone = true
    skynet.setenv(&quot;standalone&quot;, &quot;true&quot;)

    local ok, slave = pcall(skynet.newservice, &quot;cdummy&quot;)
    if not ok then
        skynet.abort()
    end
    skynet.name(&quot;.slave&quot;, slave)

else
    if standalone then
        if not pcall(skynet.newservice,&quot;cmaster&quot;) then
            skynet.abort()
        end
    end

    local ok, slave = pcall(skynet.newservice, &quot;cslave&quot;)
    if not ok then
        skynet.abort()
    end
    skynet.name(&quot;.slave&quot;, slave)
end

if standalone then
    local datacenter = skynet.newservice &quot;datacenterd&quot;
    skynet.name(&quot;DATACENTER&quot;, datacenter)
end
skynet.newservice &quot;service_mgr&quot;
pcall(skynet.newservice,skynet.getenv &quot;start&quot; or &quot;main&quot;)
skynet.exit()
</code></pre><p>end)<br>这段脚本通常会根据 standalone 配置项判断你启动的是一个 master 节点还是 slave 节点。如果是 master 节点还会进一步的通过 harbor 是否配置为 0 来判断你是否启动的是一个单节点 skynet 网络。</p>
<p>单节点模式下，是不需要通过内置的 harbor 机制做节点间通讯的。但为了兼容（因为你还是有可能注册全局名字），需要启动一个叫做 cdummy 的服务，它负责拦截对外广播的全局名字变更。</p>
<p>如果是多节点模式，对于 master 节点，需要启动 cmaster 服务作节点调度用。此外，每个节点（包括 master 节点自己）都需要启动 cslave 服务，用于节点间的消息转发，以及同步全局名字。</p>
<p>接下来在 master 节点上，还需要启动 DataCenter 服务。</p>
<p>然后，启动用于 UniqueService 管理的 service_mgr 。</p>
<p>最后，它从 config 中读取 start 这个配置项，作为用户定义的服务启动入口脚本运行。成功后，把自己退出。</p>
<p>这个 start 配置项，才是用户定义的启动脚本，默认值为 “main” 。如果你只是试玩一下 skynet ，可能有多份不同的启动脚本，那么建议你多写几份 config 文件，在里面配置不同的 start 项。examples 目录下有很多这样的例子。</p>
]]></content>
      
        <categories>
            
            <category> skynet </category>
            
        </categories>
        
        
        <tags>
            
            <tag> skynet </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (二) 数据总结]]></title>
      <url>/tensorflow_data_summary/</url>
      <content type="html"><![CDATA[<p>　　TensorFlow中的数据叫做Tensor,中文名叫做张量。由于张量要表示任意类型的数据，如照片、语音等，那么普通的简单数据类型如整型、浮点数等就很难满足需求。自然而然就想到了组合型数据类型，如一维数组、多维数组、哈希表、字符串。理论上，这些组合型数据都可以满足表示任何数据的要求，唯一的不同只是谁更适合而以。TensorFlow其内部的运行机制（要进行大量矩阵运算）决定了它的数据类型为多维数组。多维数组与矩阵天然的相似性，为数值计算提供了诸多方便。<br>　　下面分别介绍TensorFlow常用的几种数据类型：常量、变量、占位变量。它们都不是单个的数据，如一个整数，而是指多维数组，如数据类型为整数的2行2列的多维数组。</p>
<h2 id="1-Tensor-表示形式"><a href="#1-Tensor-表示形式" class="headerlink" title="1. Tensor 表示形式"></a>1. Tensor 表示形式</h2><p>　　Tensor张量的通用的简单表示形式为[T1,T2,T3…Tn]或者T1，其中T可以是TensorFlow指定的数据类型中的数字，或者由中括号括起来的元素。如下。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="number">3</span> 特殊情况，标量张量</div><div class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] 这里的T1为<span class="number">1</span>，T2为<span class="number">2</span>，T3为<span class="number">3</span></div><div class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]] 这里的T1则为[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]，T2则为[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</div><div class="line">[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]],[[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]],[[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]]</div></pre></td></tr></table></figure></p>
<h2 id="2-Tensor-维数、形状详解"><a href="#2-Tensor-维数、形状详解" class="headerlink" title="2. Tensor 维数、形状详解"></a>2. Tensor 维数、形状详解</h2><p>　　张量有维度(rank)、形状(shape)这两个属性。容易引起混淆与不理解。现解释如下。</p>
<ol>
<li><p>rank:张量的维度。一个标量的维度为0，一个一维向量的维度为1，一个2维矩阵的维度为2，一个3维空间向量矩阵的维度为3维等等。</p>
</li>
<li><p>shape:张量的形状。形状以[D0, D1, … Dn-1]的形式表示。其中的D0、D1、Dn为任意正整数1、2、3…，它的取值代表该维度中拥有的数据数量。如[2,3]表示第一维有2个元素，第二维有3个元素，即表示一个2行3列的矩阵。<br>　　在形状的中括号中有多少个数字，就代表这个张量是多少维的张量。反之亦然，多少维的张量，则中括号中就有多少个数字。如rank0的形状为[]，rank1的形状为[D0]，rank2形状为[D0, D1]，rank3的形状为[D0, D1, D2]，以此类推，rankn为[D0, D1, …Dn-1]。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">3</span> 维度为<span class="number">0</span>，标量。形状为[]</div><div class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] 维度为<span class="number">1</span>，一维向量。形状为[<span class="number">3</span>]</div><div class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]] 维度为<span class="number">2</span>，二维矩阵。形状为[<span class="number">2</span>,<span class="number">3</span>]</div><div class="line">[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]],[[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]],[[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]] 维度为<span class="number">3</span>，<span class="number">3</span>维空间矩阵。</div><div class="line">    形状为[<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>]</div></pre></td></tr></table></figure>
</li>
</ol>
<p>　　维度的读取技巧是看张量的最左边有多少个左中括号，假设为n，则这个张量就是n维张量。如上例。<br>　　形状的读取技巧是看张量的最左边的第一个中括号中，有几个元素(被一对内部中括号括起来的所有数据算一个元素)被逗号分开，假设数量为n1,则形状的第一个元素就为n1。再依次看最左边的每二个中括号中，被逗号分开的元素个数，假设为n2，则shape的第二个元素就是n2。一直这样看，直到不是左中括号[是数字为止。如上例。</p>
<h2 id="3-TensorFlow-常量"><a href="#3-TensorFlow-常量" class="headerlink" title="3. TensorFlow 常量"></a>3. TensorFlow 常量</h2><p>　　常量就是不可更改的数据。要注意，这里的数据不是单个的数据，是指多维数组。其初始化方法如下。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.constant(value, <span class="attribute">dtype</span>=None, <span class="attribute">shape</span>=None, <span class="attribute">name</span>=<span class="string">'Const'</span>, <span class="attribute">verify_shape</span>=<span class="literal">False</span>)</div></pre></td></tr></table></figure></p>
<p>　　参数:<br>value: 一个数据类型为dtype的常数值或者常数列表。<br>dtype: 常量的数据类型（可选）。<br>shape: 常量的维度（可选）。<br>name: 张量的名字（可选）。<br>verify_shape: 张量的形状是否可更改。<br>　　举例如下：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># 以一个整数数组初始化的<span class="number">1</span>维整型张量常量</div><div class="line">tensor = tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]) =&gt; 得到张量 [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]</div><div class="line"></div><div class="line"># <span class="number">2</span>维<span class="number">2</span>行<span class="number">3</span>列的浮点型张量常量，以一个浮点数<span class="number">-1.0</span>填充</div><div class="line">tensor = tf.constant(<span class="number">-1.0</span>, shape=[<span class="number">2</span>, <span class="number">3</span>]) =&gt; 得到张量 [[<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,],</div><div class="line">                                                      [<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,]]</div><div class="line"># 其它常量初始化方法如下</div><div class="line">tf.zeros(shape, dtype=tf.float32, name=None)</div><div class="line">tf.zeros([<span class="number">3</span>, <span class="number">4</span>], tf.int32) ==&gt; [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]</div><div class="line">tf.zeros_like(tensor, dtype=None, name=None, optimize=True)</div><div class="line"># 'tensor' is [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</div><div class="line">tf.zeros_like(tensor) ==&gt; [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]</div><div class="line">tf.ones(shape, dtype=tf.float32, name=None)</div><div class="line">tf.ones([<span class="number">2</span>, <span class="number">3</span>], tf.int32) ==&gt; [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]</div><div class="line">tf.ones_like(tensor, dtype=None, name=None, optimize=True)</div><div class="line"># 'tensor' is [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</div><div class="line">tf.ones_like(tensor) ==&gt; [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]</div><div class="line">tf.fill(dims, value, name=None)</div><div class="line"># Output tensor has shape [<span class="number">2</span>, <span class="number">3</span>].</div><div class="line">fill([<span class="number">2</span>, <span class="number">3</span>], <span class="number">9</span>) ==&gt; [[<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]</div><div class="line">                     [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]]</div></pre></td></tr></table></figure></p>
<p>　　同时,TensorFlow还提供序列化张量与随机张量的初始化方法。</p>
<h2 id="4-TensorFlow-变量"><a href="#4-TensorFlow-变量" class="headerlink" title="4. TensorFlow 变量"></a>4. TensorFlow 变量</h2><p>　　变量的意思就是可以改变的数据，在TensorFlow里，也同样是表达这个意思。但在TensorFlow中，哪些数据是要改变的？显尔见的，输入数据算一个，因为输入数据有很多，每个都基本不同。结果也是不断改变的，因此，输出数据也算一个，包括输入数据实际的结果与训练中输出的结果。那除了这两个外，还有什么是改变的呢？我们知道在TensorFlow中，有一种机制，不断的控制Tensor张量的流动，使其输出结果与我们的实际结果越来越近。TensorFlow的目的就是要通过学习，求得这个机制。这个机制它随着训练的样本数、训练的时间等不同而不同，因此，这种机制中，肯定有一种不断变化的数据来体现这种变化，则它也算一个要不断变化的数据。<br>　　输入、输出、TensorFlow学习机制这三个部分都有不断变化的数据，因此，理论上来说，都可以用变量来表示。但由于输入、输出的特殊性，其由训练样本直接初始化，因此，对它有特殊处理，使用一个名为placeholder占位符来表示。<strong>因此，TensorFlow中的变量特指深度学习机制中，控制输入到输出映射的可以变化的数据，这些变化数据随着训练，不断地改变，使输出的结果不断地向着正确的结果靠近。</strong><br>　　TensorFlow变量的作用，要求它有随时保存、读取的功能。因为我们训练了一段时间，中断了，我们可能想把中间训练的结果保存下来，方便下次接着这个地方继续训练。<br>　　在TensorFlow，变量是通过类来实现的，名字叫Variable。其初始化方法如下。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">tf.Variable.__init__(<span class="attribute">initial_value</span>=None, <span class="attribute">trainable</span>=<span class="literal">True</span>, <span class="attribute">collections</span>=None,</div><div class="line">    <span class="attribute">validate_shape</span>=<span class="literal">True</span>, <span class="attribute">caching_device</span>=None, <span class="attribute">name</span>=None, <span class="attribute">variable_def</span>=None,</div><div class="line">    <span class="attribute">dtype</span>=None, <span class="attribute">expected_shape</span>=None, <span class="attribute">import_scope</span>=None)</div><div class="line"></div><div class="line"><span class="comment"># 以有200个数字为0的一维常量初始化变量</span></div><div class="line">tf.Variable(tf.zeros([200]), <span class="attribute">name</span>=<span class="string">"biases"</span>)</div></pre></td></tr></table></figure></p>
<h2 id="5-TensorFlow-占位变量"><a href="#5-TensorFlow-占位变量" class="headerlink" title="5. TensorFlow 占位变量"></a>5. TensorFlow 占位变量</h2><p>　　占位的意思就是这个位置我先占了，我现在可能不用，但我将来用。占位变量也是这个意思。<br>　　在TensorFlow中，哪些变量现在不用，但以后会用呢？训练的数据成千上万，每一条都不同。当然，我们可以自己设计一种机制，在学习的时候，依次读取这些数据，然后进行训练。但可能每个人要深度学习的目的不同，可能你要识别图片，我要识别语音，他要合成诗词等等，每个人都独立地写这个通用的读取训练数据的机制，对框架的使用者来说就非常不友好了。因此，这种通用的机制应该由框架来提供，事实上，TensorFlow也提供了这样的机制，而且设计的非常好。这种机制就是placeholder（占位变量）。<br>　　占位变量就是TensorFlow用来解决读取大量训练数据问题的机制。它允许你现在不用给它赋值，随着训练的开始，它会自动把训练数据喂给训练网络学习。其初始化方法如下。<br><figure class="highlight fortran"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tf.placeholder(dtype, <span class="built_in">shape</span>=<span class="keyword">None</span>, <span class="keyword">name</span>=<span class="keyword">None</span>)</div><div class="line"></div><div class="line"># 创建一个<span class="number">2</span>维的024x1024的浮点数矩阵占位变量</div><div class="line">x = tf.placeholder(tf.float32, <span class="built_in">shape</span>=(<span class="number">1024</span>, <span class="number">1024</span>))</div></pre></td></tr></table></figure></p>
<h2 id="6-TensorFlow-运行机制详解二"><a href="#6-TensorFlow-运行机制详解二" class="headerlink" title="6. TensorFlow 运行机制详解二"></a>6. TensorFlow 运行机制详解二</h2><p>　　TensorFlow运行机制如下图所示。这篇文章我们主要介绍了TensorFlow中的数据表示形式。接下来，将详细介绍这个图中的所有数据及其来源与变化。<br><img src="/tensorflow_data_summary/tensors_flowing.gif" alt="TensorFlow 运行机制"></p>
<ol>
<li>placeholder 占位变量。在输入input结点中负责喂给训练数据。</li>
<li>Variable 变量。在这个图中有4个变量，分别为两个W，两个b。它们对TensorFlow的输出起着至关重要的作用。深度学习的目的就是要不断的修改这些变量的值，使输出与实际结果越来越近。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow (一) 基本理解]]></title>
      <url>/tensorflow_basic_understanding/</url>
      <content type="html"><![CDATA[<h2 id="1-TensorFlow-名词解释"><a href="#1-TensorFlow-名词解释" class="headerlink" title="1. TensorFlow 名词解释"></a>1. TensorFlow 名词解释</h2><ol>
<li>Tensor 是数据在TensorFlow中的约定的表示形式。就如图片在硬盘上有jpg，png等特定的表示形式一样。Tensor被设计成可以表示任何数据，它的内部实际上是一个多维数组，可以根据需要来设计。就如图片你可以是4维的数组[batch, height, width, channels]，也可以是2维的[width, height]。数据的形式完全由你自己根据需要来定，自由度非常大。</li>
<li>Flow 代表流动，在TensorFlow中则表示Tensor即数据的流动。</li>
<li>TensorFlow 因此就表示为数据流动。深度学习的本质在这里就表示通过一种特定的机制，不断地控制数据的流动，使其输出我们想要的结果。</li>
</ol>
<p><strong>TensorFlow,多维数组的流动。核心就是如何通过数组也就是数据的流动，来实现深入学习。就像是一张错综复杂的网，通过一个个结点控制网中数据的改变与流动，来实现深入学习。</strong></p>
<h2 id="2-TensorFlow-运行机制详解"><a href="#2-TensorFlow-运行机制详解" class="headerlink" title="2. TensorFlow 运行机制详解"></a>2. TensorFlow 运行机制详解</h2><p>TensorFlow运行机制如下图所示。<br><img src="/tensorflow_basic_understanding/tensors_flowing.gif" alt="TensorFlow 概念图"></p>
<ol>
<li>输入input。在这个图中，输入结节在图片的最下方，一个标示为input的椭圆形结点。在这里，你要设计输入的数据格式，即Tensor的样式。</li>
<li>数据流动。整个图的中间部分，都是数据的流动。有各种预定的处理算法来操作这些数据。通过这些操作，使其输出自己想要的结果。在这里，你要设计如何组合某些特定的操作来达到你的目的，就像图中的一样。</li>
<li>根据输出与预期结果的差异，更新数据流动中的参数。在这个图的最上方，会根据差异来更新第2步中的W和b参数。在这里要明确的一点是，这些控制参数W、b不是一个两个，而是几千个，上万个，甚至上亿、亿亿…深度学习的目的就是要求出这些参数，当以后有一个新的任务要计算时，直接可以利用这些参数，求出结果。</li>
</ol>
<h2 id="3-深度学习原理"><a href="#3-深度学习原理" class="headerlink" title="3. 深度学习原理"></a>3. 深度学习原理</h2><p> 深度学习的过程，就是要设计这样一种机制，在这种机制下，通过不断的提供学习的数据，使其从这种机制中流过，然后通过比较输出的结果与预期结果的差异来不断地调整这个机制中的参数，从而使得最终的输出离我们预定的输出越来越近，也就是越来越正确，从而达到了学习的目的。  它与普通的不是深度学习的编程的基本不同点是，不再需要为某个复杂而又有某种规律的任务来编写特定的规则，这咱规则可能极其不好用代码来表达，甚至这里面的规则太多，要全部表达而基本不可能。深度学习只要你设计好了学习的机制，这种机制，相对普通编程来说，极其简单而又好理解，然后喂给它大量的数据，它自己就会从中学到规律，很好的完成指定的任务。<br>深度学习是以前常用编码的一次飞越。它为我们解决某些特定的问题提供了一种新的机制。当然，也不是说深度学习对所有编码都可以用它，它们各自有其适用性，至少目前看来是如此。比如我们要写一个程序，判断一个数是不是偶数，普通编码就非常快。深度学习目前来看，擅长的领域为图像识别、语音识别等。</p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Tensorflow安装]]></title>
      <url>/tensorflow_install/</url>
      <content type="html"><![CDATA[<h2 id="1-TensorFlow-官网无法访问解决方法"><a href="#1-TensorFlow-官网无法访问解决方法" class="headerlink" title="1. TensorFlow 官网无法访问解决方法"></a>1. TensorFlow 官网无法访问解决方法</h2><p>通过修改host文件解决. 打开C:\Windows\System32\drivers\etc中的host文件. 添加如下内容:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">64<span class="selector-class">.233</span><span class="selector-class">.188</span><span class="selector-class">.121</span>  <span class="selector-tag">www</span><span class="selector-class">.tensorflow</span><span class="selector-class">.org</span></div></pre></td></tr></table></figure></p>
<p>其它可能能到的命令。<br><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ipconfig <span class="string">/flushdns</span>      <span class="string">//</span>清除DNS缓存内容.  </div><div class="line">ipconfig <span class="string">/displaydns</span>    <span class="string">//</span>显示DNS缓存内容</div></pre></td></tr></table></figure></p>
<h2 id="2-Linux-安装"><a href="#2-Linux-安装" class="headerlink" title="2. Linux 安装"></a>2. Linux 安装</h2><h3 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1. 安装环境"></a>1. 安装环境</h3><p>Linux(Ubuntun) + python 2.7</p>
<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">1</span>. sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-pip <span class="keyword">python</span>-dev</div><div class="line"><span class="number">2</span>. pip install tensorflow</div></pre></td></tr></table></figure>
<p>如果上面的命令无法安装，则执行下面的命令:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">1. <span class="builtin-name">export</span> <span class="attribute">TF_BINARY_URL</span>=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl</div><div class="line">2. sudo pip install --upgrade <span class="variable">$TF_BINARY_URL</span></div></pre></td></tr></table></figure></p>
<p>注意：在aliyun上，安装时，可能会提示找不到python.h文件，而执行<br><figure class="highlight q"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="built_in">get</span> install python-<span class="built_in">dev</span></div></pre></td></tr></table></figure></p>
<p>时，可能会提示在源中找不到相关文件，这时执行下面的命令可以解决相关问题：<br><figure class="highlight q"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="built_in">get</span> <span class="keyword">update</span></div></pre></td></tr></table></figure></p>
<p>update是更新软件列表，upgrade是更新软件。</p>
<p>如果出现 AttributeError: type object ‘NewBase’ has no attribute ‘is_abstract’<br>这个问题，应该是six包安装有问题，可以卸载原有版本，重新安装：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash"> sudo pip uninstall six</span></div><div class="line"><span class="meta">$</span><span class="bash"> sudo pip install six --upgrade</span></div></pre></td></tr></table></figure></p>
<p>一般来说six包的安装位置是/usr/lib/python2.7/dist-packages，建议先试前者（工作站上也是前者），如果six版本还是没有改变，则指定安装位置，如下：<br><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo pip install six <span class="params">--upgrade</span> <span class="params">--target=</span><span class="string">"/usr/lib/python2.7/dist-packages"</span></div></pre></td></tr></table></figure></p>
<h2 id="3-Windows-安装"><a href="#3-Windows-安装" class="headerlink" title="3. Windows 安装"></a>3. Windows 安装</h2><p>TensorFlow现在在windows上只支持64位的 python 3.5.打开<a href="https://www.python.org/downloads/release/python-352/" target="_blank" rel="external">python 3.5下载官网</a>，下载合适版本。<br>TensorFlow 分两个版本，分别是是否支持GPU。支持GPU的版本则学习的时候速度更快，但必须显卡支持，这样的显卡通常是nvidia英伟达显卡。如果没有明确支持TensorFlow的显卡，则安装CPU版本的，学习一般足够了。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># CPU 版本。 这两个版本的安装选一个就可以了。</span></div><div class="line">pip install --upgrade https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/tensorflow/</span>windows<span class="regexp">/cpu/</span>tensorflow-<span class="number">0.12</span>.<span class="number">0</span>rc1-cp35-cp35m-win_amd64.whl</div><div class="line"><span class="comment"># GPU 版本</span></div><div class="line">pip install --upgrade https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/tensorflow/</span>windows<span class="regexp">/gpu/</span>tensorflow_gpu-<span class="number">0.12</span>.<span class="number">0</span>rc1-cp35-cp35m-win_amd64.whl</div></pre></td></tr></table></figure></p>
<p>如果在使用的过程中，出现“No module named “_pywrap_tensorflow” and/or DLL load failed”，则要安装[Visual C++ 2015 redistributable (x64 version)]<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http<span class="variable">s:</span>//www.microsoft.<span class="keyword">com</span>/<span class="keyword">en</span>-us/download/details.aspx?id=<span class="number">53587</span></div></pre></td></tr></table></figure></p>
<h2 id="4-测试安装"><a href="#4-测试安装" class="headerlink" title="4. 测试安装"></a>4. 测试安装</h2><p>打开命令行，输入如下命令，如果运行正常，则代表安装正确。<br>$ python<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import tensorflow as tf</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sess = tf.Session()</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(sess.run(hello))</span></div><div class="line">Hello, TensorFlow!</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; a = tf.constant(10)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; b = tf.constant(32)</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(sess.run(a + b))</span></div><div class="line">42</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[中医之我思]]></title>
      <url>/think_in_Chinese_medicine/</url>
      <content type="html"><![CDATA[<h2 id="1-阴阳五行学说"><a href="#1-阴阳五行学说" class="headerlink" title="1. 阴阳五行学说"></a>1. 阴阳五行学说</h2><p>金木水火土,相生相克.<br>肝木,心火,脾土,肺金,肾水.</p>
<h2 id="2-中医发展原理"><a href="#2-中医发展原理" class="headerlink" title="2. 中医发展原理"></a>2. 中医发展原理</h2><p>中医现在为什么难发展，其中一个原因，我想是因为中医无法像西医那样，找到看得见摸得着的方便验证的理论方法。中医是一门根据经验效果发展起来的科学。它的理论体系是为了方便学习、记忆、使用而创建的工具体系，而不是真正的原理体系。但是不了解真正的原理，并不妨碍其学习、使用。就像你有一个万能工具，有必要知道他的真正原理吗，用就是了。在这个由经验方法发展起来的中医体系中，人们为了解释其治病的机理，而想出了各种理论体系，像什么阴阳、八纲、六经、脏腑、经络、三焦、卫气营血等等。每个理论体系都很正确，因为他们由经验而总结而来，却不能准确得像西医那样。而每个人由于学习的经验不同，就又造成了每个人对同一个病人的治病方法又不同。随着科技的发展，中医肯定最终能发展如西医一样，用精确的解释来说明其治病的原理，而不像现在这样模模糊糊，形而上学。<br>中医以阴阳为根，这是一种很重要的思想。世间万物都可归结为阴阳。非阴即阳，非阳即阴。这是一个大的概念。如温度分高低，就就是阳、低就是阴；高度分高低，高就是阳，低就是阴；动静中，动即阳，静则阴，如此等等。它把事物分成两个对立变化的方面。这两个方面在变化的过程中，随着阴生阳长或阳生阴长而产生无数种中间状态。当然，根据常识，阴阳的最中间的状态也比较重要。像六经中的少阳、厥阴等。<br>八纲为阴阳、表里、寒热、虚实，也根于阴阳。它将人身体的状态从不同的方面来分阴阳。要注意这里的表里、寒热、虚实与普通的相似又不同的地方。</p>
<h2 id="3-中医治病机理"><a href="#3-中医治病机理" class="headerlink" title="3. 中医治病机理"></a>3. 中医治病机理</h2><p>中医理论根由阴阳。治病则在药。经过几千年的发展，中医对药积累了无数的经验，经过组方，完成了方证对应。也对人体病的发展有了很多经验积累，病的传变、好坏。通过对这些经验的总结，而完成了中医的治病方法。因此，中医可以治病，关键是能不能在总结的经验中，找到或者推断出治那个病的理法方药。</p>
<h2 id="4-其它"><a href="#4-其它" class="headerlink" title="4. 其它"></a>4. 其它</h2><p>肺主气，在肺为气，在外为卫。心主血，在心为血，在外为营。</p>
]]></content>
      
        <categories>
            
            <category> 中医 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 中医 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[loader Pomelo 研究]]></title>
      <url>/loader_pomelo_study/</url>
      <content type="html"><![CDATA[<h2 id="1-基本类库"><a href="#1-基本类库" class="headerlink" title="1. 基本类库"></a>1. 基本类库</h2><ol>
<li>should: test framework agnostic BDD-style assertions</li>
<li>mocha: simple, flexible, fun test framework</li>
<li>express: Fast, unopinionated, minimalist web framework</li>
<li>connect: High performance middleware framework </li>
<li>socket.io: node.js realtime framework server</li>
<li>generic-pool: Generic resource pooling for Node.JS</li>
<li>mysql: A node.js driver for mysql. It is written in JavaScript</li>
<li>async:Higher-order functions and common patterns for asynchronous code</li>
<li>socket.io-client:</li>
<li>pomelo-aoi：pomelo-schedule is the aoi module used in the demo of pomelo.</li>
<li>crc:Module for calculating Cyclic Redundancy Check (CRC) for Node.js and the Browser.</li>
<li>pomelo-bt: pomelo-bt是pomelo项目中AI模块所依赖的行为树模块，提供了基本的行为树实现。</li>
<li>pomelo-pathfinding: pomelo-pathfinding is the pathfinding module used in lord of pomelo.</li>
<li>pomelo-collection: Pomelo-collection is the module for basic data structure in Node.JS.</li>
<li>pomelo-logger</li>
<li>pomelo-monitor: monitor the operating-system and process information</li>
<li>pomelo-sync-plugin</li>
<li>pomelo-masterha-plugin</li>
<li>underscore: JavaScript’s functional programming helper library.</li>
<li>node-zookeeper-client: A pure Javascript ZooKeeper client for Node.js.</li>
<li>webkit-devtools-agent: Webkit devtools agent that leverages remote debugging and profiling of nodejs applications using the built-in webkit inspector.</li>
</ol>
<h2 id="2-模块"><a href="#2-模块" class="headerlink" title="2. 模块"></a>2. 模块</h2><h3 id="2-1-dao-模块"><a href="#2-1-dao-模块" class="headerlink" title="2.1 dao 模块"></a>2.1 dao 模块</h3><p>通过通用的sql语句,查询相关信息,再通过回调方法,返回调用函数.</p>
]]></content>
      
        <categories>
            
            <category> pomelo </category>
            
        </categories>
        
        
        <tags>
            
            <tag> pomelo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Markdown 教程]]></title>
      <url>/markdown/</url>
      <content type="html"><![CDATA[<h1 id="MarkDown-语法样本"><a href="#MarkDown-语法样本" class="headerlink" title="MarkDown 语法样本"></a><center>MarkDown 语法样本</center></h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">center</span>&gt;</span> <span class="tag">&lt;/<span class="name">center</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>/&gt;</span></div><div class="line">如果另起一行，只需在当前行结尾加 2 个空格</div><div class="line">如果是要起一个新段落，只需要空出一行即可。</div></pre></td></tr></table></figure>
<h4 id="1-标题语法"><a href="#1-标题语法" class="headerlink" title="1. 标题语法"></a>1. 标题语法</h4><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="section">== 一级标题</span></div><div class="line"><span class="bullet">-- </span>二级标题</div></pre></td></tr></table></figure>
<p> <strong><em>标题=-的数量必须大于等于2个</em></strong></p>
<h4 id="2-加粗"><a href="#2-加粗" class="headerlink" title="2. 加粗"></a>2. 加粗</h4><figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 一级加粗</div><div class="line">## 二级加粗</div><div class="line">### 三级加粗</div><div class="line">#### 四级加粗</div><div class="line">##### 五级加粗</div><div class="line">###### 六级加粗</div></pre></td></tr></table></figure>
<p><strong><em>很多语法前都可以加入加粗标记,来设置文字大小</em></strong></p>
<h4 id="3-粗斜体标亮"><a href="#3-粗斜体标亮" class="headerlink" title="3. 粗斜体标亮"></a>3. 粗斜体标亮</h4><p> 以*或者_来标记.二者是等价的.下面以*为例说明.<br> 一个*号(*)是斜体.两个*号(**)是粗体,三个*号(***)是粗斜体<br> <em>斜体文本</em>    <em>斜体文本</em><br> <strong>粗体文本</strong>    <strong>粗体文本</strong><br> <strong><em>粗斜体文本</em></strong>    <strong><em>粗斜体文本</em></strong><br> <code>标亮</code></p>
<h4 id="4-列表"><a href="#4-列表" class="headerlink" title="4. 列表"></a>4. 列表</h4><p>无序列表以<em>,+,-开头,有序列表以1.开头.序号与内容中间必须有空格.有序列表的数 字,当前面没有加粗符号时,没有用,它自动从1开始递增(chrome markdown preview plus).<br>无序列表可以用星号</em>、加号+或者连字符-<br>无序列表</p>
<ul>
<li>1</li>
</ul>
<ul>
<li>2</li>
</ul>
<ul>
<li>3</li>
</ul>
<p>有序表</p>
<ol>
<li>1</li>
<li>2</li>
<li>3</li>
</ol>
<h5 id="5-引用"><a href="#5-引用" class="headerlink" title="5. 引用"></a>5. 引用</h5><p> 引用:行首以&gt;开头.效果如下.</p>
<blockquote>
<p>一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。</p>
</blockquote>
<h4 id="6-代码"><a href="#6-代码" class="headerlink" title="6. 代码"></a>6. 代码</h4><p>单行代码以`code`表示.<br>多行代码以```code```表示.```必须独占一行.<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Hello, markdown!"</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="7-链接"><a href="#7-链接" class="headerlink" title="7. 链接"></a>7. 链接</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[<span class="string">网页链接</span>](<span class="link">http://www.baidu.com</span>)<span class="xml"><span class="tag">&lt;<span class="name">br</span>/&gt;</span></span></div><div class="line">![<span class="string">图片链接</span>](<span class="link">http://ww4.sinaimg.cn/bmiddle/aa397b7fjw1dzplsgpdw5j.jpg</span>)</div></pre></td></tr></table></figure>
<h4 id="8-横线"><a href="#8-横线" class="headerlink" title="8. 横线"></a>8. 横线</h4><p>下面所有的效果一样,全是横线<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="string">*</span> <span class="string">*</span> <span class="string">*</span></div><div class="line"><span class="string">***</span></div><div class="line"><span class="string">****</span></div><div class="line"><span class="string">*****</span></div><div class="line"><span class="bullet">-</span> <span class="bullet">-</span> <span class="bullet">-</span></div><div class="line"><span class="meta">---</span></div><div class="line"><span class="string">____---</span></div><div class="line"><span class="bullet">-</span><span class="bullet">--------------------</span></div><div class="line"><span class="string">_</span> <span class="string">_</span> <span class="string">_</span></div><div class="line"><span class="string">_</span> <span class="string">_</span> <span class="string">_____</span></div></pre></td></tr></table></figure></p>
<hr>
<h4 id="9-表格"><a href="#9-表格" class="headerlink" title="9. 表格"></a>9. 表格</h4><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="params">| Tables        |</span> Are           <span class="params">| Cool  |</span></div><div class="line"><span class="params">| ------------- |</span><span class="symbol">:-------------</span><span class="symbol">:|</span> -----<span class="symbol">:|</span></div><div class="line"><span class="params">| col 3 is      |</span> right-aligned <span class="params">| 1600 |</span></div><div class="line"><span class="params">| col 2 is      |</span> centered      <span class="params">|   12 |</span></div><div class="line"><span class="params">| zebra stripes |</span> are neat      <span class="params">|    1 |</span></div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>Tables</th>
<th style="text-align:center">Are</th>
<th style="text-align:right">Cool</th>
</tr>
</thead>
<tbody>
<tr>
<td>col 3 is</td>
<td style="text-align:center">right-aligned</td>
<td style="text-align:right">1600</td>
</tr>
<tr>
<td>col 2 is</td>
<td style="text-align:center">centered</td>
<td style="text-align:right">12</td>
</tr>
<tr>
<td>zebra stripes</td>
<td style="text-align:center">are neat</td>
<td style="text-align:right">1</td>
</tr>
</tbody>
</table>
]]></content>
      
        <categories>
            
            <category> markdown </category>
            
        </categories>
        
        
        <tags>
            
            <tag> markdown </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Git 实用干货总结（附异地私有Git仓库实现办法）]]></title>
      <url>/git_private_repo_and_multi_ssh_key/</url>
      <content type="html"><![CDATA[<h2 id="1-网盘-Git-实现异地、免费、安全、私有的版本管理"><a href="#1-网盘-Git-实现异地、免费、安全、私有的版本管理" class="headerlink" title="1. 网盘+Git 实现异地、免费、安全、私有的版本管理"></a>1. 网盘+Git 实现异地、免费、安全、私有的版本管理</h2><p>相信很多人都想拥有自己的私有版本管理平台，无论是文档管理还是代码管理，都是非常方<br>便的。如果用Github的私有仓库，每年的支出都是一笔不小的费用，而且Github有些地方网<br>络访问速度慢；而如果用Github的免费版本，那就私密安全性又得不到保证。 另外如果自己<br>搭建Git服务器，对于普通大众来说又没有必要，况且又耗时费力而不讨好。</p>
<p>这里一种非常好的替代方法就是在网盘中创建Git仓库，然后利用网盘来进行仓库的同步。<br>从而实现多地、免费、安全、私有的版本管理。在使用的过程中，只要保证网盘的同步即可。<br>比如在工作的地方，把代码或文档更新到同步盘中；回到家中，打开同步盘，它会自动同步。<br>然后再用Git更新即可。这样就保证了各个地方的版本同步而且又方便安全。</p>
<p>具体的操作方法如下：</p>
<ol>
<li><p>申请网盘。一定要申请那种带有<strong>同步盘</strong>功能的网盘。这里有几个大坑：</p>
<ul>
<li>有的网盘，它对于大量的小文件支持不是很好，即有时一些小文件它会同步不到，而Git<br>提交时，会生成大量的小文件，从而造成同步时Git仓库的损坏。<br><img src="/git_private_repo_and_multi_ssh_key/0.png" alt=""></li>
<li><p>有的网盘，并没有同步盘功能，或者同步盘功能是要收费的，则这些尽量不选择。</p>
<p>对于网盘的选择，个人推荐<strong>微云</strong>。</p>
</li>
</ul>
</li>
<li><p>创建本地仓库。在网盘的同步盘中创建Git仓库（要利用网盘来实现异地同步）。命令如下<br>（注意在git bash中运行，下同）：</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git init <span class="comment">--bare</span></div></pre></td></tr></table></figure>
</li>
<li><p>克隆本地仓库。命令如下，注意斜杠与反斜杠：</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">git clone F:/weiyun/repo/test</div><div class="line">```  </div><div class="line">![](<span class="number">1.</span>png)</div><div class="line"></div><div class="line">通过上述步骤，一个异地、免费、安全、私有的版本管理系统就搭建好了。</div><div class="line"></div><div class="line">对于Git提交中生成很多小文件从而影响网盘同步效率的问题，可以在同步盘的Git仓库中执行 如下命令中的任何一个来解决：</div><div class="line">* `git repack -d` 命令,它会将git仓库中所有没有打包的碎片文件打包到一个大的文件中,</div><div class="line">从而大大减少仓库下objects文件夹中碎片文件的数量。</div><div class="line">* `git repack -a -d` 命令，它会将所有的文件（包括已打包的）打包到一个文件中,这会生成</div><div class="line">一个新的文件。这个命令要**慎用**,因为它会增加网盘的同步负担（已同步的文件相当于要重新同步）.</div><div class="line">* `git gc` 等价于 `git repack -a -d`。</div><div class="line"></div><div class="line">最后，给大家一个自动将所有Git仓库小文件打包的脚本（[gitbat.bat](gitbat.bat)）：</div></pre></td></tr></table></figure>
</li>
</ol>
<p>@echo off<br>for /d %%i in (*) do @echo. &amp;&amp;@echo ——————————————————– &amp;&amp;@echo %%i &amp;&amp;@cd %cd%\%%i &amp;&amp;@git repack -d<br>pause<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">比如在你的同步盘F:\weiyun\repo中，有很多你的Git仓库a、b、c...。那么在F:\weiyun\repo 中，创建gitbat.bat文件，然后把上面的内容复制到里面。以后每个月执行一下该脚本即可， 则所有以前提交生成的小文件都会利用命令`git repack -d`打包。</div><div class="line">![](<span class="number">2.</span>png)</div><div class="line"></div><div class="line">## <span class="number">2.</span> Git Key 管理</div><div class="line">#### ssh key 生成。使用如下命令：</div></pre></td></tr></table></figure></p>
<p>ssh-keygen -t rsa -C iwifigame@126.com -f ~/.ssh/iwifigame<br>ssh-keygen -t rsa -C liyongjin2009@gmail.com -f ~/.ssh/liyongjin<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#### Git 自动使用多个 ssh key(以**Github**为例)</div><div class="line"><span class="number">1.</span> 生成ssh key.</div></pre></td></tr></table></figure></p>
<p>ssh-keygen -t rsa -C iwifigame@126.com -f ~/.ssh/iwifigame<br>ssh-keygen -t rsa -C liyongjin2009@gmail.com -f ~/.ssh/liyongjin<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="bullet">2. </span>在Github中添加ssh key,具体方法可以百度搜索下，很简单。</div><div class="line"><span class="bullet">3. </span>在~/.ssh/目录下新建config文件，用于配置各个公私钥相对应的主机.内容如下:</div></pre></td></tr></table></figure></p>
<p>Host liyongjin<br>Hostname github.com<br>User liyongjin<br>IdentityFile ~/.ssh/liyongjin<br>Host iwifigame<br>HostName github.com<br>User iwifigames<br>IdentityFile ~/.ssh/iwifigame<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">4</span>. 测试连接情况<span class="comment">(**可跳过**)</span>。以`ssh -T git@Host`的形式测试。Host为上面config文件里定义的Host 名字。如：</div></pre></td></tr></table></figure></p>
<p>ssh -T git@liyongjin<br>ssh -T git@iwifigame<br><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">5. 修改**<span class="selector-tag">git</span>仓库地址**。将@后的<span class="keyword">github</span>.<span class="keyword">com</span>改为<span class="keyword">config</span>文件里<span class="keyword">Host</span>定义的地址。如下：</div></pre></td></tr></table></figure></p>
<p>git clone git@github.com:iwifigame/vimrc.git    改为<br>git clone git@iwifigame:iwifigame/vimrc.git<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Git会根据config中的配置，使用其中Hostname指定的服务器地址与dentityFile指定的 私钥来进行版本管理。从而达到使用多个 ssh key 的目的。</div><div class="line">6. 其它配置。如果你使用**smartgit**，则要在菜单edit/preference中，选中Authentication 选项下的Use<span class="built_in"> system </span>SSH clinet。才可以使用多个ssh key。其它Git软件应该也要做相应的处理， 才能使用系统默认的ssh client。  </div><div class="line">![](3.png)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">## 3. Git 版本管理</span></div><div class="line"><span class="comment">#### 远程版本提交撤销。有两个方法，如下。</span></div><div class="line">1. 撤销最后的一个版本(**注意版本安全，可能引起别人版本错误**)。</div></pre></td></tr></table></figure></p>
<p>git reset –hard HEAD~1<br>git push -f<br><figure class="highlight coq"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">2.</span> 使用<span class="built_in">revert</span>命令（更安全的做法）。相当于重新提交一个指定版本的反修改。</div></pre></td></tr></table></figure></p>
<p>git revert HEAD<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#### 只克隆最近的一个版本。</div><div class="line">对于大型仓库，这个命令能大大减少网络、硬盘、 **时间**等资源的使用。命令如下：</div></pre></td></tr></table></figure></p>
<p>git clone –depth=1<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">## 4. Git 常见问题处理</div><div class="line">#### 文件换行符问题（LF转成CRLF错误）。有如下两种处理办法：</div><div class="line">1. 一劳永逸的方法。打开  **~/.gitconfig** 文件，设置**safecrlf**为false。</div></pre></td></tr></table></figure></p>
<p>[core]<br>       autocrlf = input<br>       safecrlf = false<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">2. 另一种方法。就是用vim打开该文件，</div><div class="line">执行`<span class="builtin-name">set</span> <span class="attribute">ff</span>=dos` 或者 `<span class="builtin-name">set</span> <span class="attribute">fileformat</span>=dos`，这两个命令的区别只是一个是简写的形式。</div><div class="line">它的作用是将文件的格式设置为dos格式，即windows下的格式。</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">## Git 其它</span></div><div class="line">* 使用TortoiseGit，如果出现如下错误：</div></pre></td></tr></table></figure></p>
<p>isconnected no supported authentication methods available(server sent: publickey，<br>keyboard interactive<br>```<br>则按如下的步骤解决：</p>
<pre><code>1. 找到TortoiseGit -&gt; Settings -&gt; Network
2. 将SSH client指向你的ssh程序。它的位置一般在C:\Program Files\Git\usr\bin\ssh.exe
</code></pre><ul>
<li>git pull = git fetch and git merge</li>
<li>只克隆最近的几次提交。对于大型项目非常实用。<br>git clone git://xxoo –depth 1</li>
</ul>
]]></content>
      
        <categories>
            
            <category> git </category>
            
            <category> github </category>
            
        </categories>
        
        
        <tags>
            
            <tag> git </tag>
            
            <tag> github </tag>
            
            <tag> ssh key </tag>
            
            <tag> 网盘 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo一条龙：从建站到托管到Github Pages到最后域名绑定的详细教程]]></title>
      <url>/hexo_from_build_to_github_pages_and_domain/</url>
      <content type="html"><![CDATA[<h2 id="1-Hexo-简介"><a href="#1-Hexo-简介" class="headerlink" title="1. Hexo 简介"></a>1. Hexo 简介</h2><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>简单的说，就是Hexo可以根据你写的Markdown文章，生成一个个好看的静态网页。然后，你可以把这些静态网页托管在你的服务器（如github pages、阿里云等）或者Hexo中，别人就可以通过你配置的网址，访问你写的文章。</p>
<h2 id="2-Hexo-安装"><a href="#2-Hexo-安装" class="headerlink" title="2. Hexo 安装"></a>2. Hexo 安装</h2><p>安装 Hexo 需要安装下面两个程序。</p>
<ul>
<li>Node.js</li>
<li>Git</li>
</ul>
<p>安装完毕后，只要使用 npm 即可完成 Hexo 的安装。打开命令行界面，执行下面的命令：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install -g hexo-<span class="keyword">cli</span></div></pre></td></tr></table></figure></p>
<p>如果npm安装的速度太慢，这是由于npm镜像在国外的缘故。可按如下方法解决：<br>npm config set key value 命令，设置npm指定的镜像地址,这里设置为淘宝的地址。<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">npm config <span class="keyword">set</span> registry <span class="comment">https:</span>//<span class="comment">registry.npm.taobao.org</span> </div><div class="line">npm <span class="comment">info underscore</span> （这个只是为了检验上面的设置命令是否成功，若成功，会返回<span class="comment">[</span>指定包<span class="comment">]</span>的信息）</div></pre></td></tr></table></figure></p>
<h2 id="3-Hexo-建站"><a href="#3-Hexo-建站" class="headerlink" title="3. Hexo 建站"></a>3. Hexo 建站</h2><p>Hexo 安装完成后，打开命令行，切换到要建站的文件夹必须是空的文件夹，要不命令出错。执行下列命令，将会建站一个基本的Hexo站点。<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo init</div><div class="line">npm <span class="keyword">install</span></div></pre></td></tr></table></figure></p>
<p>运行界面如下。如果出现 “Start blogging with Hexo!” 字样，就代表安装成功了。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_0.png" alt=""><br>Hexo 安装成功后，文件夹结构如下。其中node_modules里面放的是node模块，基本不用去管；scaffolds里面放的是文章模版文件，当你使用Hexo新建文章时，将使用这些模版创建文件；source中放着所有你写的文章;themes中放置着网站的主题，主题负责整个网站的显示样式，可以在网上找到各种样式的主题，如Next,uno,yilia等。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_1.png" alt=""><br>至此，Hexo 就建站完毕，非常简单。执行下面的两条命令，可以先预览一下建站效果。<br><figure class="highlight verilog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo <span class="keyword">generate</span></div><div class="line">hexo server</div></pre></td></tr></table></figure></p>
<p>这两条命令的执行效果如下，可以通过 <a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a>访问建好的网站。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_2.png" alt=""><br><img src="/hexo_from_build_to_github_pages_and_domain/1_3.png" alt=""></p>
<h2 id="4-Hexo-基本配置"><a href="#4-Hexo-基本配置" class="headerlink" title="4. Hexo 基本配置"></a>4. Hexo 基本配置</h2><p>Hexo 的基本配置文件为你建站的文件夹中的_config.yml文件。在该文件中，可以设置网站的标题、语言（中文、英语等)、时区等；也可以设置网站的网址；还有其它如目录、文章、分类、标签、日期模式等。当然，比较重要的一个配置是设置Hexo的主题。<br>Hexo 的主题设置方法（以Next主题为例）如下。在Hexo网站文件夹下，执行命令：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/iissnan/hexo-theme-<span class="keyword">next</span> themes/<span class="keyword">next</span></div></pre></td></tr></table></figure></p>
<p>也可以直接下载Next文件，放在themes/next下。与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开 站点配置文件_config.yml， 找到 theme 字段，并将其值更改为 next。如下。<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theme: <span class="keyword">next</span></div></pre></td></tr></table></figure></p>
<p>到此，NexT 主题安装完成。最好使用<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">hexo clean</span></div></pre></td></tr></table></figure></p>
<p>来清除 Hexo 的缓存。最后，就可以通过执行下面两条命令，查看主题效果。在主题的配置文件/themes/next/_config.yml中，可以配置markdown中的代码样式（如代码采用黑色背景）、网站logo、导航栏样式与位置、百度统计等。<br><figure class="highlight verilog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo <span class="keyword">generate</span></div><div class="line">hexo server</div></pre></td></tr></table></figure></p>
<p><img src="/hexo_from_build_to_github_pages_and_domain/1_4.png" alt=""><br>在_config.yml中，可以设置将Hexo生成的静态页面部署到指定的服务器中，如github。但是，在我的使用过程中，有各种奇怪的问题，因此，不推荐配置该选项，推荐使用本文中Hexo github 配置章节中的方法。</p>
<h2 id="5-Hexo-github-配置"><a href="#5-Hexo-github-配置" class="headerlink" title="5. Hexo github 配置"></a>5. Hexo github 配置</h2><p>Hexo 建站完毕后，可以在本地服务器上查看自己写的文章，但是我们一般想随时随地随人都可以查看我们的文章。当然，我匀可以把Hexo托管到云服务器上，但是更方便的做法是把它托管到github pages上，既省钱又方便。过程如下。</p>
<ol>
<li>创建github pages。打开<a href="https://github.com/" target="_blank" rel="external">github官网</a>,注册账号。然后创建一个仓库，仓库的名字为username.github.io。username为你注册时的用户名。这个仓库是特殊约定的，因此就决定了每个帐号只能有一个仓库来创建github pages。创建完成后，你就可以通过<a href="http://username.github.io" target="_blank" rel="external">http://username.github.io</a> 来访问这个网站。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_5.png" alt=""></li>
<li>克隆github pages仓库到Hexo网站的deploy文件夹中。这里面用到了一个github多用户名技巧，当你有多个github账号时，非常实用，请参考我的另一篇文章<a href="">1. 网盘+Git 实现异地、免费、安全、私有的版本管理</a><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone git<span class="variable">@hiOlive</span><span class="symbol">:hiOlive/hiolive</span>.github.io.git deploy</div></pre></td></tr></table></figure>
</li>
</ol>
<p>将我们之前创建的repo克隆到本地，新建一个目录叫做.deploy用于存放克隆的代码。</p>
<p>创建一个deploy脚本文件</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">@<span class="keyword">echo</span> off</div><div class="line">cp -R public/* <span class="keyword">deploy</span></div><div class="line"><span class="keyword">cd</span> <span class="keyword">deploy</span></div><div class="line">git add .</div><div class="line">git commit -m <span class="string">"update"</span></div><div class="line">git push origin master</div></pre></td></tr></table></figure>
<h2 id="6-github-自定义域名"><a href="#6-github-自定义域名" class="headerlink" title="6. github 自定义域名"></a>6. github 自定义域名</h2><h2 id="7-Hexo-写文章"><a href="#7-Hexo-写文章" class="headerlink" title="7. Hexo 写文章"></a>7. Hexo 写文章</h2><h4 id="写文章配置"><a href="#写文章配置" class="headerlink" title="写文章配置"></a>写文章配置</h4><p>打开站点配置文件，修改如下地方。<br>new_post_name: :year-:month-:day-:title.md # File name of new posts<br>post_asset_folder: true  # 在post中使用资源文件，在使用hexo n 文件时，会同步创建同名资源文件夹。</p>
<h4 id="方便地插入图片"><a href="#方便地插入图片" class="headerlink" title="方便地插入图片"></a>方便地插入图片</h4><ol>
<li><p>安装hexo-asset-image库，在Hexo目录下执行命令：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install https:<span class="regexp">//gi</span>thub.com<span class="regexp">/CodeFalling/</span>hexo-asset-image --save</div></pre></td></tr></table></figure>
</li>
<li><p>使用hexo n 创建新文件，会在source/_posts同时创建相同名字的md文件与文件夹。</p>
</li>
<li>将要插入的图片放在第2步中创建的文件夹中，假设图片名字是a.png。</li>
<li>在md文件中直接写上图片名字即可引用图片。如下。<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">!<span class="selector-attr">[]</span>(<span class="selector-tag">a</span><span class="selector-class">.png</span>)</div></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="站内文章英文地址"><a href="#站内文章英文地址" class="headerlink" title="站内文章英文地址"></a>站内文章英文地址</h4><p>网站文章最好是英文址。英文地址设置方法如下。<br>修改_config.yml中的permalink如下：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">permalink:</span> <span class="symbol">:url/</span></div></pre></td></tr></table></figure></p>
<p>同时在写的文章中插入url属性，如下。<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">---</span></div><div class="line"><span class="attr">layout:</span> <span class="string">post</span></div><div class="line"><span class="attr">title:</span> <span class="string">Hexo一条龙：从建站到托管到Github</span> <span class="string">Pages到最后域名绑定的详细教程</span></div><div class="line"><span class="attr">date:</span> <span class="number">2017</span><span class="bullet">-09</span><span class="bullet">-01</span> <span class="number">11</span><span class="string">:12:50</span></div><div class="line"><span class="attr">url:</span> <span class="string">hexo_from_build_to_github_pages_and_domain</span></div><div class="line"><span class="attr">tags:</span> <span class="string">[Hexo,</span> <span class="string">web,</span> <span class="string">git,</span> <span class="string">github]</span></div><div class="line"><span class="attr">categories:</span> <span class="string">[Web]</span></div><div class="line"><span class="meta">---</span></div></pre></td></tr></table></figure></p>
<h4 id="百度统计"><a href="#百度统计" class="headerlink" title="百度统计"></a>百度统计</h4><ol>
<li>打开<a href="https://tongji.baidu.com" target="_blank" rel="external">百度统计官网</a>，注册账号，添加网站。</li>
<li>点击网页最上面的管理菜单。可看到如下页面。点击获取代码。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_11.png" alt=""></li>
<li>复制到next theme的配置文件中的 baidu_analytics字段中。如下。<figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># <span class="keyword">Baidu </span>Analytics ID</div><div class="line"><span class="keyword">baidu_analytics: </span><span class="number">79</span>aef6896eb90dbc14242b196015b9e9</div></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="/hexo_from_build_to_github_pages_and_domain/1_12.png" alt=""></p>
<h4 id="添加文章阅读次数-LeanCloud"><a href="#添加文章阅读次数-LeanCloud" class="headerlink" title="添加文章阅读次数 LeanCloud"></a>添加文章阅读次数 LeanCloud</h4><p>首先注册LeanCloud账号。官网地址为<a href="https://leancloud.cn" target="_blank" rel="external">LeanClound 官网</a></p>
<ol>
<li>创建应用。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_6.png" alt=""></li>
<li>点击新创建的应用。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_7.png" alt=""></li>
<li>点击左边的存储，然后点击新建Class,新建名为Counter的Class。如下图。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_10.png" alt=""><br><img src="/hexo_from_build_to_github_pages_and_domain/1_9.png" alt=""></li>
<li>然后点击左边的设置，点开应用Key。就可以看到App ID与App Key。如下图。<br><img src="/hexo_from_build_to_github_pages_and_domain/1_8.png" alt=""></li>
<li><p>修改next theme的配置文件_config.yml，在themes\next文件夹下。找到如下内容，把第4步中的ID与Key写入如下位置即可。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># You can visit https://leancloud.cn get AppID and AppKey.</span></div><div class="line"><span class="attr">leancloud_visitors:</span></div><div class="line"><span class="attr">  enable:</span> <span class="literal">true</span></div><div class="line"><span class="attr">  app_id:</span> <span class="string">Ju0g9TyWNmr28UUi493xOsxG-gzGzoHss</span> </div><div class="line"><span class="attr">  app_key:</span> <span class="string">p5CLocEvdKWa1SAXkH9Lcd6z</span></div></pre></td></tr></table></figure>
</li>
<li><p>利用命令 hexo g 重新生成网站文章，即可以网站中，看到阅读统计。</p>
</li>
</ol>
<h4 id="引用站内文章"><a href="#引用站内文章" class="headerlink" title="引用站内文章"></a>引用站内文章</h4>


<p><a href="hexo_from_build_to_github_pages_and_domain"></a><br><br></p>
<h4 id="打赏"><a href="#打赏" class="headerlink" title="打赏"></a>打赏</h4><h4 id="百度Google收录"><a href="#百度Google收录" class="headerlink" title="百度Google收录"></a>百度Google收录</h4><h4 id="评论添加（基于来必力）"><a href="#评论添加（基于来必力）" class="headerlink" title="评论添加（基于来必力）"></a>评论添加（基于来必力）</h4>]]></content>
      
        <categories>
            
            <category> Web </category>
            
        </categories>
        
        
        <tags>
            
            <tag> git </tag>
            
            <tag> github </tag>
            
            <tag> Hexo </tag>
            
            <tag> web </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
